{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b3fbaa",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c303b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    ")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f128622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af732a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.14 | packaged by conda-forge | (main, Oct 22 2025, 22:56:31) [Clang 19.1.7 ]\n",
      "MLflow version: 3.6.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48735661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.16.1\n",
      "GPU physiques: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU logiques: [LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 20:38:33.012630: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-11-20 20:38:33.012650: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-11-20 20:38:33.012656: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-11-20 20:38:33.013045: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-20 20:38:33.013075: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPU physiques:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"GPU logiques:\", tf.config.list_logical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9bce8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 6), (8000, 6), (10000, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"dataset/train_50K.csv\")\n",
    "df_val = pd.read_csv(\"dataset/val_50K.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_50K.csv\")\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31545748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.sample(frac=0.5, random_state=42)\n",
    "# df_test = df_test.sample(frac=0.5, random_state=42)\n",
    "# df_val = df_val.sample(frac=0.5, random_state=42)\n",
    "# df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a82727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv(\"train_50K.csv\", index=False)\n",
    "# df_val.to_csv(\"val_50K.csv\", index=False)\n",
    "# df_test.to_csv(\"test_50K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2419609c",
   "metadata": {},
   "source": [
    "# Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e7650bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rssjb ok a r v. qsdsdqs'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def soft_preprocess(text):\n",
    "    # Minuscules\n",
    "    text = str(text).lower()\n",
    "    # Supprimer mentions\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    # Supprimer uniquenment #\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "    # # Supprimer mots d'1 lettre\n",
    "    # text = re.sub(r\"\\b[a-z]\\b\", \"\", text)\n",
    "    # Nettoyer espaces multiples\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "text = \"RSSJb @qbjhbq #ok a r    v.   qsdsdqs \"\n",
    "soft_preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f64c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"text\"].apply(soft_preprocess)\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(soft_preprocess)\n",
    "df_val[\"text\"] = df_val[\"text\"].apply(soft_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ed0ba5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne: 13 mots\n",
      "Médiane: 12 mots\n",
      "Max: 40 mots\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(text.split()) for text in df_train[\"text\"]]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.axvline(x=500, color=\"r\", linestyle=\"--\", label=\"max_length=500\")\n",
    "plt.xlabel(\"Nombre de mots\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Moyenne: {np.mean(lengths):.0f} mots\")\n",
    "print(f\"Médiane: {np.median(lengths):.0f} mots\")\n",
    "print(f\"Max: {np.max(lengths)} mots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "29c0632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Voir tous les optimiseurs disponibles\n",
    "# from tensorflow.keras import optimizers\n",
    "# import inspect\n",
    "\n",
    "# print(\"Optimiseurs disponibles:\")\n",
    "# for name in dir(optimizers):\n",
    "#     obj = getattr(optimizers, name)\n",
    "#     if inspect.isclass(obj) and issubclass(obj, optimizers.Optimizer):\n",
    "#         print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a57b2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = None\n",
    "MAX_TWEET_LENGTH = 50\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "EMBEDDING_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12cec686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration MLflow\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25af79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load\n",
    "# df_train = pd.read_csv(\"train_100K.csv\")\n",
    "# df_val = pd.read_csv(\"val_100K.csv\")\n",
    "# df_test = pd.read_csv(\"test_100K.csv\")\n",
    "# df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "582d9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_TWEET_LENGTH,  # padding\n",
    "    # standardize=None,\n",
    "    # split=\"whitespace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0955490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vocabulaire: 33655 mots\n"
     ]
    }
   ],
   "source": [
    "text_vectorizer.adapt(df_train[\"text\"].values)\n",
    "vocab_size = len(text_vectorizer.get_vocabulary())\n",
    "VOCAB_SIZE = vocab_size\n",
    "print(f\" Vocabulaire: {vocab_size} mots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "94acb486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer pipeline tensorflow pour optimser le temps d'execution\n",
    "def make_dataset(df, shuffle=True):\n",
    "    texts = df[\"text\"].values\n",
    "    labels = df[\"target\"].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (texts, labels)\n",
    "    )  # Créer dataset tensorflow => data en paire (texts, labels) => optimisé le traitement\n",
    "    if shuffle:  # data mélangé, ordre aléatoire => Meilleur generalisation\n",
    "        dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(\n",
    "        tf.data.AUTOTUNE\n",
    "    )  # prefetch GPU calcule batch 1 // CPU prépare batch2 => gain de temps d'execution, AUTOTUNE=>s'adapte à GPU M2\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52e06264",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = make_dataset(df_train, shuffle=True)\n",
    "data_val = make_dataset(df_val, shuffle=False)\n",
    "data_test = make_dataset(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ml_simple\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_6 (Text  (None, 50)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 50, 32)            1076960   \n",
      "                                                                 \n",
      " global_average_pooling1d_9  (None, 32)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1081185 (4.12 MB)\n",
      "Trainable params: 1081185 (4.12 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 16s 49ms/step - loss: 0.6503 - accuracy: 0.6019 - val_loss: 0.5312 - val_accuracy: 0.7502 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.4819 - accuracy: 0.7854 - val_loss: 0.4922 - val_accuracy: 0.7771 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.4085 - accuracy: 0.8359 - val_loss: 0.4986 - val_accuracy: 0.7732 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.8679\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.3547 - accuracy: 0.8679 - val_loss: 0.5267 - val_accuracy: 0.7704 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.8952Restoring model weights from the end of the best epoch: 2.\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.3017 - accuracy: 0.8952 - val_loss: 0.5570 - val_accuracy: 0.7673 - lr: 5.0000e-04\n",
      "Epoch 5: early stopping\n",
      "ok train\n",
      "Entrainement terminé => 54.51 secondes\n",
      "\n",
      "Logging de 5 époques (EarlyStopping peut avoir arrêté avant 20)\n",
      "\n",
      "train_loss: 0.3983137011528015\n",
      "train_accuracy: 0.847000002861023\n",
      "\n",
      "val_loss: 0.4921592175960541\n",
      "val_accuracy: 0.7771250009536743\n",
      "\n",
      "test_loss: 0.5190250277519226\n",
      "test_accuracy: 0.7634000182151794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/30 20:45:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmp1l6ygzgr/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmp1l6ygzgr/model/data/model/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'ML_Simple_softPreProcess_33655'.\n",
      "Created version '1' of model 'ML_Simple_softPreProcess_33655'.\n"
     ]
    }
   ],
   "source": [
    "# Run mlflow\n",
    "with mlflow.start_run(run_name=f\"ML_Simple_softPreProcess_{VOCAB_SIZE}\"):\n",
    "\n",
    "    # Enregistrement du temps de début\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Log\n",
    "    params = {\n",
    "        \"vocab_size\": VOCAB_SIZE,  # =>>>>>> Taille du vocab réel\n",
    "        \"max_length\": MAX_TWEET_LENGTH,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"optimizer\": \"adamW\",\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"train_samples\": len(df_train),\n",
    "        \"val_samples\": len(df_val),\n",
    "        \"test_samples\": len(df_test),\n",
    "        \"architecture\": \"Embedding_GAP\",\n",
    "        \"gpu\": \"Apple M2\",\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Modèle\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            # Couche de vectorisation\n",
    "            layers.Input(shape=(1,), dtype=tf.string),\n",
    "            text_vectorizer,\n",
    "            layers.Embedding(\n",
    "                input_dim=VOCAB_SIZE,  # Taille du vocab\n",
    "                output_dim=32,  # Dimensions des embeddings \n",
    "                # input_length=max_tweet_length => optionnel car gap toujours (batch, 32), obligatoire avec flatten\n",
    "            ),\n",
    "            # GAP\n",
    "            layers.GlobalAveragePooling1D(),  # calcul la moyenne des dimensions\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"ml_simple\",\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=AdamW(\n",
    "            learning_rate=0.001\n",
    "        ),  # => meilleure régulation (Régularisation L2 intégrée)\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        # Arrêt précoce si la validation ne s'améliore plus\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=3,  # Attendre 3 epochs sans amélioration\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        # Réduction du learning rate si plateau\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,  # Réduire le LR de moitié\n",
    "            patience=2,  # Attendre 2 epochs avant de réduire\n",
    "            verbose=1,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        data_train,\n",
    "        validation_data=data_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "    )\n",
    "    print(\"ok train\")\n",
    "\n",
    "    # Calcul du temps d'entraînement total\n",
    "    training_time = time.time() - start_time\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "    print(f\"Entrainement terminé => {training_time:.2f} secondes\")\n",
    "\n",
    "    # Nombre réel d'époques exécutées\n",
    "    actual_epochs = len(history.history[\"loss\"])\n",
    "    print(\n",
    "        f\"\\nLogging de {actual_epochs} époques (EarlyStopping peut avoir arrêté avant {EPOCHS})\"\n",
    "    )\n",
    "\n",
    "    # Logger les metriques par épochs\n",
    "    for epoch in range(actual_epochs):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_accuracy\", history.history[\"accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_accuracy\", history.history[\"val_accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "\n",
    "    # Évaluation\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(data_val, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, verbose=0)\n",
    "\n",
    "    # Log des métriques de base dans MLflow\n",
    "    mlflow.log_metric(\"train_loss\", train_loss)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    print(f\"\\ntrain_loss: {train_loss}\")\n",
    "    print(f\"train_accuracy: {train_accuracy}\")\n",
    "    print(f\"\\nval_loss: {val_loss}\")\n",
    "    print(f\"val_accuracy: {val_accuracy}\")\n",
    "    print(f\"\\ntest_loss: {test_loss}\")\n",
    "    print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Pred\n",
    "    # Train\n",
    "    y_train_pred_proba = model.predict(data_train, verbose=0).flatten()  # Probabilités\n",
    "    y_train_pred = (y_train_pred_proba > 0.5).astype(int)  # => seuil 0.5\n",
    "    y_train_true = df_train[\"target\"].values\n",
    "\n",
    "    # Val\n",
    "    y_val_pred_proba = model.predict(data_val, verbose=0).flatten()\n",
    "    y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "    y_val_true = df_val[\"target\"].values\n",
    "\n",
    "    # Test\n",
    "    y_test_pred_proba = model.predict(data_test, verbose=0).flatten()\n",
    "    y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
    "    y_test_true = df_test[\"target\"].values\n",
    "\n",
    "    def calcul_metriques(y_true, y_pred, y_pred_proba):\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        return precision, recall, f1, roc_auc\n",
    "\n",
    "    # Calcul des métriques\n",
    "    train_precision, train_recall, train_f1, train_roc_auc = calcul_metriques(\n",
    "        y_train_true, y_train_pred, y_train_pred_proba\n",
    "    )\n",
    "\n",
    "    val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val_true, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "\n",
    "    test_precision, test_recall, test_f1, test_roc_auc = calcul_metriques(\n",
    "        y_test_true, y_test_pred, y_test_pred_proba\n",
    "    )\n",
    "\n",
    "    # Métriques train\n",
    "    mlflow.log_metric(\"train_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # Métriques val\n",
    "    mlflow.log_metric(\"val_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    # Métriques test\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    # Overfitting check\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    # Visualisation\n",
    "    # Train\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    epochs_range = range(1, actual_epochs + 1)\n",
    "    # Accuracy\n",
    "    ax1.plot(\n",
    "        epochs_range,\n",
    "        history.history[\"accuracy\"],\n",
    "        \"b-\",\n",
    "        label=\"Train Accuracy\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax1.plot(\n",
    "        epochs_range,\n",
    "        history.history[\"val_accuracy\"],\n",
    "        \"r:\",\n",
    "        label=\"Val Accuracy\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax1.set_title(\"Accuracy Train - Val\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    # Loss\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"loss\"], \"b-\", label=\"Train Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"val_loss\"], \"r:\", label=\"Val Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.set_title(\"Loss Train - Val\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Sauvegarde et log dans MLflow\n",
    "    plt.savefig(\"training_history.png\")\n",
    "    mlflow.log_artifact(\"training_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Courbe ROC pour train, val,test\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train_true, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val_true, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test_true, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - Train/Validation/Test\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Sauvegarder l'image\n",
    "    plt.savefig(\"roc_curve_comparaison.png\")\n",
    "    mlflow.log_artifact(\"roc_curve_comparaison.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Créer la signature\n",
    "    from mlflow.models.signature import infer_signature\n",
    "\n",
    "    # Input signature\n",
    "    input_example = df_train[\"text\"].head(3).values\n",
    "    sample_predictions = model.predict(input_example, verbose=0)\n",
    "\n",
    "    # Inférer la signature\n",
    "    signature = infer_signature(input_example, sample_predictions)\n",
    "    # Sauvegarde du modèle\n",
    "    mlflow.tensorflow.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=f\"ML_Simple_softPreProcess_{VOCAB_SIZE}\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            f\"pandas=={pd.__version__}\",\n",
    "            f\"numpy=={np.__version__}\",\n",
    "            f\"tensorflow=={tf.__version__}\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Ajout de tags pour faciliter la recherche et l'organisation\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"DL_Simple\",\n",
    "            \"architecture\": \"dl_Simple\",\n",
    "            \"dataset\": \"twitter_50K\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772e88a",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed3af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06f65d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"text\"].apply(soft_preprocess)\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(soft_preprocess)\n",
    "df_val[\"text\"] = df_val[\"text\"].apply(soft_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f55e40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = None\n",
    "MAX_TWEET_LENGTH = 50\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "EMBEDDING_DIM = 100\n",
    "WINDOW = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation simple \n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "train_tokens = [tokenize(text) for text in df_train[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bc19414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x30e51ce90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_word2vec = Word2Vec(\n",
    "    sentences=train_tokens,\n",
    "    vector_size=EMBEDDING_DIM,  #  vector_size 100 dimensions\n",
    "    window=WINDOW,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,  # Skip-gram\n",
    "    seed=42,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "modele_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "204ecd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire Word2Vec: 14983 mots\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulaire Word2Vec: {len(modele_word2vec.wv)} mots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer matrice d'embedding pré-entraînée\n",
    "\n",
    "# Créer TextVectorization\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_TWEET_LENGTH,\n",
    "    standardize=None,  # déjà préprocessé\n",
    "    split=\"whitespace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22db293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(df_train[\"text\"].values)\n",
    "vocab = text_vectorizer.get_vocabulary()\n",
    "vocab_size = len(vocab)\n",
    "VOCAB_SIZE = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08b89d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots trouvés dans Word2Vec: 14983/50906 (29.4%)\n"
     ]
    }
   ],
   "source": [
    "# Mtrice d'embedding à partir de Word2Vec\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    if word in modele_word2vec.wv:\n",
    "        embedding_matrix[i] = modele_word2vec.wv[word]\n",
    "        words_found += 1\n",
    "    # Sinon reste à zéro (mots inconnus)\n",
    "\n",
    "print(\n",
    "    f\"Mots trouvés dans Word2Vec: {words_found}/{vocab_size} ({100*words_found/vocab_size:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4cf1e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = make_dataset(df_train, shuffle=True)\n",
    "data_val = make_dataset(df_val, shuffle=False)\n",
    "data_test = make_dataset(df_test, shuffle=False)\n",
    "data_train_eval = make_dataset(df_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41911ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration MLflow\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77898622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word2vec_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (Text  (None, 50)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 50, 100)           5090600   \n",
      "                                                                 \n",
      " global_average_pooling1d_3  (None, 100)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                6464      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5099177 (19.45 MB)\n",
      "Trainable params: 5099177 (19.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 13s 46ms/step - loss: 0.6062 - accuracy: 0.6767 - val_loss: 0.5288 - val_accuracy: 0.7409 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 0.4959 - accuracy: 0.7764 - val_loss: 0.5038 - val_accuracy: 0.7688 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 11s 45ms/step - loss: 0.4456 - accuracy: 0.8115 - val_loss: 0.5061 - val_accuracy: 0.7707 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8289\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.4166 - accuracy: 0.8289 - val_loss: 0.5177 - val_accuracy: 0.7619 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8446Restoring model weights from the end of the best epoch: 2.\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.3855 - accuracy: 0.8446 - val_loss: 0.5126 - val_accuracy: 0.7692 - lr: 5.0000e-04\n",
      "Epoch 5: early stopping\n",
      "ok train\n",
      "Temps d'entraînement : 55.62 secondes\n",
      "\n",
      "Logging de 5 époques (EarlyStopping peut avoir arrêté avant 20)\n",
      "\n",
      "Métriques finales :\n",
      "Train - Loss: 0.4280, Accuracy: 0.8247\n",
      "Val   - Loss: 0.5038, Accuracy: 0.7688\n",
      "Test  - Loss: 0.5299, Accuracy: 0.7558\n",
      "INFO:tensorflow:Assets written to: /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmp5p0ubhw6/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmp5p0ubhw6/model/data/model/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'DL_Simple_Word2Vec_50906' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'DL_Simple_Word2Vec_50906'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modèle sauvegardé\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"DL_Simple_Word2Vec_softPreProcess_{VOCAB_SIZE}\"):\n",
    "\n",
    "    # Enregistrement du temps de début\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Log des paramètres\n",
    "    params = {\n",
    "        \"vocab_size\": VOCAB_SIZE,\n",
    "        \"max_length\": MAX_TWEET_LENGTH,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,\n",
    "        \"optimizer\": \"adamW\",\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"train_samples\": len(df_train),\n",
    "        \"val_samples\": len(df_val),\n",
    "        \"test_samples\": len(df_test),\n",
    "        \"architecture\": \"Word2Vec_EMB_GAP\",\n",
    "        \"gpu\": \"Apple M2\",\n",
    "        \"w2v_window\": WINDOW,\n",
    "        \"w2v_min_count\": 2,\n",
    "        \"embedding_trainable\": True,\n",
    "        \"use_gap\": True,\n",
    "        \"dense_1_units\": 64,\n",
    "        \"dropout_1\": 0.3,\n",
    "        \"dense_2_units\": 32,\n",
    "        \"dropout_2\": 0.3,\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Modèle\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(1,), dtype=tf.string),\n",
    "            text_vectorizer,\n",
    "            # Embedding avec poids Word2Vec\n",
    "            layers.Embedding(\n",
    "                input_dim=VOCAB_SIZE,\n",
    "                output_dim=EMBEDDING_DIM,\n",
    "                weights=[embedding_matrix],\n",
    "                trainable=True,\n",
    "                mask_zero=False,\n",
    "            ),\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"word2vec_model\",\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=AdamW(learning_rate=LEARNING_RATE),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    \n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=2, verbose=1\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        data_train,\n",
    "        validation_data=data_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    print(\"ok train\")\n",
    "\n",
    "    # Temps d'entraînement\n",
    "    training_time = time.time() - start_time\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "    print(f\"Temps d'entraînement : {training_time:.2f} secondes\")\n",
    "\n",
    "    # Nombre d'époques réelles\n",
    "    actual_epochs = len(history.history[\"loss\"])\n",
    "    mlflow.log_metric(\"actual_epochs\", actual_epochs)\n",
    "    print(\n",
    "        f\"\\nLogging de {actual_epochs} époques \"\n",
    "        f\"(EarlyStopping peut avoir arrêté avant {EPOCHS})\"\n",
    "    )\n",
    "\n",
    "    # Log des métriques par époque\n",
    "    for epoch in range(actual_epochs):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_accuracy\", history.history[\"accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_accuracy\", history.history[\"val_accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "\n",
    "    # Évaluation avec model.evaluate()\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(data_val, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, verbose=0)\n",
    "\n",
    "    # Log des métriques de base\n",
    "    mlflow.log_metric(\"train_loss\", train_loss)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    print(f\"\\nMétriques finales :\")\n",
    "    print(f\"Train - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test  - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Prédictions pour métriques avancées\n",
    "    y_train_pred_proba = model.predict(data_train_eval, verbose=0).flatten()\n",
    "    y_train_pred = (y_train_pred_proba > 0.5).astype(int)\n",
    "    y_train_true = df_train[\"target\"].values\n",
    "\n",
    "    y_val_pred_proba = model.predict(data_val, verbose=0).flatten()\n",
    "    y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "    y_val_true = df_val[\"target\"].values\n",
    "\n",
    "    y_test_pred_proba = model.predict(data_test, verbose=0).flatten()\n",
    "    y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
    "    y_test_true = df_test[\"target\"].values\n",
    "\n",
    "    # Fonction de calcul des métriques avancées\n",
    "    def calcul_metriques(y_true, y_pred, y_pred_proba):\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        return precision, recall, f1, roc_auc\n",
    "\n",
    "    # Calcul des métriques\n",
    "    train_precision, train_recall, train_f1, train_roc_auc = calcul_metriques(\n",
    "        y_train_true, y_train_pred, y_train_pred_proba\n",
    "    )\n",
    "\n",
    "    val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val_true, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "\n",
    "    test_precision, test_recall, test_f1, test_roc_auc = calcul_metriques(\n",
    "        y_test_true, y_test_pred, y_test_pred_proba\n",
    "    )\n",
    "\n",
    "    # Log des métriques\n",
    "    # Train\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # Validation\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    # Test\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    # Métriques d'overfitting\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    # Visualisation - Accuracy et Loss\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    epochs_range = range(1, actual_epochs + 1)\n",
    "\n",
    "    # Accuracy\n",
    "    ax1.plot(\n",
    "        epochs_range,\n",
    "        history.history[\"accuracy\"],\n",
    "        \"b-\",\n",
    "        label=\"Train Accuracy\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax1.plot(\n",
    "        epochs_range,\n",
    "        history.history[\"val_accuracy\"],\n",
    "        \"r:\",\n",
    "        label=\"Val Accuracy\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax1.set_title(\"Accuracy Train - Val\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Loss\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"loss\"], \"b-\", label=\"Train Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"val_loss\"], \"r:\", label=\"Val Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.set_title(\"Loss Train - Val\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_history.png\")\n",
    "    mlflow.log_artifact(\"training_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Courbe ROC pour train, val, test\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train_true, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val_true, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test_true, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - DL Simple Word2Vec Sentiment Analysis\")\n",
    "    plt.legend(loc=\"lower right\", fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"DL_Simple_Word2Vec_roc_curve_comparaison.png\")\n",
    "    mlflow.log_artifact(\"DL_Simple_Word2Vec_roc_curve_comparaison.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Créer la signature\n",
    "    from mlflow.models.signature import infer_signature\n",
    "\n",
    "    # Input signature\n",
    "    input_example = df_train[\"text\"].head(3).values\n",
    "    sample_predictions = model.predict(input_example, verbose=0)\n",
    "\n",
    "    # Inférer la signature\n",
    "    signature = infer_signature(input_example, sample_predictions)\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    mlflow.tensorflow.log_model(\n",
    "        model,\n",
    "        name=\"model\",\n",
    "        registered_model_name=f\"DL_Simple_Word2Vec_{VOCAB_SIZE}\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            f\"pandas=={pd.__version__}\",\n",
    "            f\"numpy=={np.__version__}\",\n",
    "            f\"tensorflow=={tf.__version__}\",\n",
    "            f\"gensim=={gensim.__version__}\",\n",
    "        ],\n",
    "    )\n",
    "    print(\"\\nModèle sauvegardé\")\n",
    "\n",
    "    # Tags\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"DL_Simple\",\n",
    "            \"architecture\": \"dl_Simple\",\n",
    "            \"embedding_type\": \"Word2Vec_pretrained\",\n",
    "            \"embedding_trainable\": \"True\",\n",
    "            \"dataset\": \"twitter_50K\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f9faf",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b70d7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = None\n",
    "MAX_TWEET_LENGTH = 50\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "EMBEDDING_DIM = 100\n",
    "LEARNING_RATE = 0.001\n",
    "GLOVE_PATH = \"/Users/skanderzahi/Desktop/glove.twitter.27B/glove.twitter.27B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb82cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"text\"].apply(soft_preprocess)\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(soft_preprocess)\n",
    "df_val[\"text\"] = df_val[\"text\"].apply(soft_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dca96e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension des embeddings GloVe: 100D\n",
      "GloVe chargé: 1193514 mots\n",
      "Exemples: ['<user>', '.', ':', 'rt', ',', '<repeat>', '<hashtag>', '<number>', '<url>', '!', 'i', 'a', '\"', 'the', '?', 'you', 'to', '(', '<allcaps>', '<elong>', ')', 'me', 'de', '<smile>', '！', 'que', 'and', '。', '-', 'my', 'no', '、', 'is', 'it', '…', 'in', 'n', 'for', '/', 'of', 'la', \"'s\", '*', 'do', \"n't\", 'that', 'on', 'y', \"'\", 'e', 'o', 'u', 'en', 'this', 'el', 'so', 'be', \"'m\", 'with', 'just', '>', 'your', '^', 'like', 'have', 'te', 'at', '？', 'love', 'se', 'are', '<', 'm', 'r', 'if', 'all', 'b', '・', 'not', 'but', 'we', 'es', 'ya', '&', 'follow', 'up', 'what', 'get', 'lol', 'un', '♥', 'lo']\n"
     ]
    }
   ],
   "source": [
    "# Chargement des embeddings\n",
    "glove_embeddings = {}\n",
    "embedding_dim_found = None\n",
    "\n",
    "with open(GLOVE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "\n",
    "        # Vérifier la dimension au premier mot\n",
    "        if embedding_dim_found is None:\n",
    "            embedding_dim_found = len(vector)\n",
    "            print(f\"Dimension des embeddings GloVe: {embedding_dim_found}D\")\n",
    "\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "print(f\"GloVe chargé: {len(glove_embeddings)} mots\")\n",
    "print(f\"Exemples: {list(glove_embeddings.keys())[:92]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52d144ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulaire TensorFlow: 50905 mots\n"
     ]
    }
   ],
   "source": [
    "# Vectorisation\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_TWEET_LENGTH,\n",
    "    standardize=None,  # Déjà préprocessé\n",
    "    split=\"whitespace\",\n",
    ")\n",
    "\n",
    "text_vectorizer.adapt(df_train[\"text\"].values)\n",
    "vocab = text_vectorizer.get_vocabulary()\n",
    "vocab_size = len(vocab)\n",
    "VOCAB_SIZE = vocab_size\n",
    "\n",
    "print(f\"Vocabulaire TensorFlow: {vocab_size} mots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b085779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création de la matrice d'embedding...\n",
      "Couverture GloVe: 19275/50905 mots (37.9%)\n",
      "Mots non trouvés: 31628 (exemples: [\"i'm\", \"it's\", \"don't\", \"can't\", '2', \"i'll\", \"didn't\", \"that's\", \"you're\", \"i've\"])\n"
     ]
    }
   ],
   "source": [
    "# Créer matrice d'embedding depuis GloVe\n",
    "print(\"Création de la matrice d'embedding...\")\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "words_found = 0\n",
    "words_not_found = []\n",
    "# Mapping\n",
    "for i, word in enumerate(vocab):\n",
    "    if word in glove_embeddings:\n",
    "        embedding_matrix[i] = glove_embeddings[word]\n",
    "        words_found += 1\n",
    "    else:\n",
    "        # Mots non trouvés: vecteur aléatoire ou zéro\n",
    "        # Option 1: Zéro (par défaut)\n",
    "        # Option 2: Aléatoire\n",
    "        # embedding_matrix[i] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
    "        if i > 1:  # Ne pas logger padding et [UNK]\n",
    "            words_not_found.append(word)\n",
    "\n",
    "coverage = 100 * words_found / vocab_size\n",
    "print(f\"Couverture GloVe: {words_found}/{vocab_size} mots ({coverage:.1f}%)\")\n",
    "print(f\"Mots non trouvés: {len(words_not_found)} (exemples: {words_not_found[:10]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "893871f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = make_dataset(df_train, shuffle=True)\n",
    "data_val = make_dataset(df_val, shuffle=False)\n",
    "data_test = make_dataset(df_test, shuffle=False)\n",
    "data_train_eval = make_dataset(df_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c140728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4adbad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"glove_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_5 (Text  (None, 50)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " glove_embedding (Embedding  (None, 50, 100)           5090500   \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling1d_8  (None, 100)               0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5099077 (19.45 MB)\n",
      "Trainable params: 5099077 (19.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 24s 63ms/step - loss: 0.6110 - accuracy: 0.6644 - val_loss: 0.5248 - val_accuracy: 0.7459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.4830 - accuracy: 0.7825 - val_loss: 0.4911 - val_accuracy: 0.7765 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 10s 42ms/step - loss: 0.4126 - accuracy: 0.8298 - val_loss: 0.5092 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3690 - accuracy: 0.8499\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "250/250 [==============================] - 12s 48ms/step - loss: 0.3687 - accuracy: 0.8501 - val_loss: 0.5139 - val_accuracy: 0.7744 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8694Restoring model weights from the end of the best epoch: 2.\n",
      "250/250 [==============================] - 12s 47ms/step - loss: 0.3356 - accuracy: 0.8693 - val_loss: 0.5396 - val_accuracy: 0.7691 - lr: 5.0000e-04\n",
      "Epoch 5: early stopping\n",
      "ok train\n",
      "Entraînement terminé: 72.19 secondes\n",
      "\n",
      "Logging de 5 époques (EarlyStopping peut avoir arrêté avant 20)\n",
      "\n",
      "train_loss: 0.4020611047744751\n",
      "train_accuracy: 0.8393124938011169\n",
      "\n",
      "val_loss: 0.49106207489967346\n",
      "val_accuracy: 0.7764999866485596\n",
      "\n",
      "test_loss: 0.5175043344497681\n",
      "test_accuracy: 0.760699987411499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/30 20:38:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmp2etbe3s8/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmp2etbe3s8/model/data/model/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 149ms/step\n",
      "\n",
      "Modèle sauvegardé\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'GloVe_Twitter_100D_50905'.\n",
      "Created version '1' of model 'GloVe_Twitter_100D_50905'.\n"
     ]
    }
   ],
   "source": [
    "# Run Mlflow\n",
    "with mlflow.start_run(run_name=f\"DL_Simple_GloVe_{VOCAB_SIZE}\"):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Paramètres avec info GloVe\n",
    "    params = {\n",
    "        \"vocab_size\": VOCAB_SIZE,\n",
    "        \"max_length\": MAX_TWEET_LENGTH,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"embedding_dim\": EMBEDDING_DIM,  # 100D\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"train_samples\": len(df_train),\n",
    "        \"val_samples\": len(df_val),\n",
    "        \"test_samples\": len(df_test),\n",
    "        \"architecture\": \"GloVe_EMB_GAP\",\n",
    "        \"gpu\": \"Apple M2\",\n",
    "        \"glove_source\": \"glove.twitter.27B.100d\",\n",
    "        \"glove_coverage\": f\"{coverage:.1f}%\",\n",
    "        \"embedding_trainable\": True,\n",
    "        \"use_gap\": True,\n",
    "        \"dense_1_units\": 64,\n",
    "        \"dropout_1\": 0.3,\n",
    "        \"dense_2_units\": 32,\n",
    "        \"dropout_2\": 0.3,\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Modèle\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(1,), dtype=tf.string),\n",
    "            text_vectorizer,\n",
    "            # Embedding 100D avec poids GloVe\n",
    "            layers.Embedding(\n",
    "                input_dim=VOCAB_SIZE,\n",
    "                output_dim=EMBEDDING_DIM,  # 100 dimensions\n",
    "                weights=[embedding_matrix],  # Poids GloVe pré-entraînés\n",
    "                trainable=True,\n",
    "                mask_zero=False,  # Ignore padding\n",
    "                name=\"glove_embedding\",\n",
    "            ),\n",
    "            # Architecture identique\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ],\n",
    "        name=\"glove_model\",\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=AdamW(learning_rate=LEARNING_RATE),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3, restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.5, patience=2, verbose=1\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        data_train,\n",
    "        validation_data=data_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "    )\n",
    "    print(\"ok train\")\n",
    "\n",
    "    # Temps d'entraînement\n",
    "    training_time = time.time() - start_time\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "    print(f\"Entraînement terminé: {training_time:.2f} secondes\")\n",
    "\n",
    "    # Nombre d'époques réelles\n",
    "    actual_epochs = len(history.history[\"loss\"])\n",
    "    print(\n",
    "        f\"\\nLogging de {actual_epochs} époques \"\n",
    "        f\"(EarlyStopping peut avoir arrêté avant {EPOCHS})\"\n",
    "    )\n",
    "\n",
    "    # Log des métriques par époque\n",
    "    for epoch in range(actual_epochs):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_accuracy\", history.history[\"accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_accuracy\", history.history[\"val_accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "\n",
    "    # Évaluation avec model.evaluate()\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(data_val, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", train_loss)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    print(f\"\\ntrain_loss: {train_loss}\")\n",
    "    print(f\"train_accuracy: {train_accuracy}\")\n",
    "    print(f\"\\nval_loss: {val_loss}\")\n",
    "    print(f\"val_accuracy: {val_accuracy}\")\n",
    "    print(f\"\\ntest_loss: {test_loss}\")\n",
    "    print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Prédictions pour métriques avancées\n",
    "    y_train_pred_proba = model.predict(data_train_eval, verbose=0).flatten()\n",
    "    y_train_pred = (y_train_pred_proba > 0.5).astype(int)\n",
    "    y_train_true = df_train[\"target\"].values\n",
    "\n",
    "    y_val_pred_proba = model.predict(data_val, verbose=0).flatten()\n",
    "    y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "    y_val_true = df_val[\"target\"].values\n",
    "\n",
    "    y_test_pred_proba = model.predict(data_test, verbose=0).flatten()\n",
    "    y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
    "    y_test_true = df_test[\"target\"].values\n",
    "\n",
    "    # Fonction de calcul des métriques avancées\n",
    "    def calcul_metriques(y_true, y_pred, y_pred_proba):\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        return precision, recall, f1, roc_auc\n",
    "\n",
    "    train_precision, train_recall, train_f1, train_roc_auc = calcul_metriques(\n",
    "        y_train_true, y_train_pred, y_train_pred_proba\n",
    "    )\n",
    "\n",
    "    val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val_true, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "\n",
    "    test_precision, test_recall, test_f1, test_roc_auc = calcul_metriques(\n",
    "        y_test_true, y_test_pred, y_test_pred_proba\n",
    "    )\n",
    "\n",
    "    # Log métriques train\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # Log métriques val\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    # Log métriques test\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    # Métriques d'overfitting\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    # Visualisation - Accuracy et Loss\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    epochs_range = range(1, actual_epochs + 1)\n",
    "\n",
    "    # Accuracy\n",
    "    ax1.plot(epochs_range, history.history[\"accuracy\"], \"b-\", label=\"Train Accuracy\")\n",
    "    ax1.plot(epochs_range, history.history[\"val_accuracy\"], \"r:\", label=\"Val Accuracy\")\n",
    "    ax1.set_title(\"Accuracy Train - Val\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Loss\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"loss\"], \"b-\", label=\"Train Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"val_loss\"], \"r:\", label=\"Val Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.set_title(\"Loss Train - Val\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"glove_training_history.png\")\n",
    "    mlflow.log_artifact(\"glove_training_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Courbe ROC\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train_true, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val_true, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test_true, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - GloVe Embeddings\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"glove_roc_curve_comparaison.png\")\n",
    "    mlflow.log_artifact(\"glove_roc_curve_comparaison.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Créer la signature\n",
    "    from mlflow.models.signature import infer_signature\n",
    "\n",
    "    # Input signature\n",
    "    input_example = df_train[\"text\"].head(3).values\n",
    "    sample_predictions = model.predict(input_example, verbose=0)\n",
    "\n",
    "    # Inférer la signature\n",
    "    signature = infer_signature(input_example, sample_predictions)\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "    mlflow.tensorflow.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=f\"GloVe_Twitter_100D_{VOCAB_SIZE}\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            f\"pandas=={pd.__version__}\",\n",
    "            f\"numpy=={np.__version__}\",\n",
    "            f\"tensorflow=={tf.__version__}\",\n",
    "        ],\n",
    "    )\n",
    "    print(\"\\nModèle sauvegardé\")\n",
    "\n",
    "    # Tags\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"DL_Simple\",\n",
    "            \"architecture\": \"dl_Simple\",\n",
    "            \"embedding_type\": \"GloVe_pretrained\",\n",
    "            \"embedding_trainable\": \"True\",\n",
    "            \"embedding_source\": \"glove.twitter.27B.100d\",\n",
    "            \"dataset\": \"twitter_50K\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c967be",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e65560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e16afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "USE_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd652afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/train_50K.csv\")\n",
    "df_val = pd.read_csv(\"dataset/val_50K.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_50K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f82fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "def soft_preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "df_train[\"text\"] = df_train[\"text\"].apply(soft_preprocess)\n",
    "df_val[\"text\"] = df_val[\"text\"].apply(soft_preprocess)\n",
    "df_test[\"text\"] = df_test[\"text\"].apply(soft_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e07c64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipiline tf\n",
    "def make_dataset(df, shuffle=True):\n",
    "    texts = df[\"text\"].values\n",
    "    labels = df[\"target\"].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((texts, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "data_train = make_dataset(df_train, shuffle=True)\n",
    "data_train_eval = make_dataset(df_train, shuffle=False)\n",
    "data_val = make_dataset(df_val, shuffle=False)\n",
    "data_test = make_dataset(df_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d6e949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config MLflow\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "899ccdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement de Universal Sentence Encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 19:45:18.194031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"use_dense_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"use_dense_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ use_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m)                 │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ use_embedding (\u001b[38;5;33mLambda\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,545</span> (674.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m172,545\u001b[0m (674.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,545</span> (674.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m172,545\u001b[0m (674.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 56ms/step - accuracy: 0.7604 - loss: 0.4977 - val_accuracy: 0.7688 - val_loss: 0.4757 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57ms/step - accuracy: 0.7644 - loss: 0.4955 - val_accuracy: 0.7729 - val_loss: 0.4765 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 63ms/step - accuracy: 0.7680 - loss: 0.4926 - val_accuracy: 0.7756 - val_loss: 0.4900 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7713 - loss: 0.4923\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 76ms/step - accuracy: 0.7701 - loss: 0.4984 - val_accuracy: 0.7788 - val_loss: 0.4833 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 114ms/step - accuracy: 0.7686 - loss: 0.4907 - val_accuracy: 0.7754 - val_loss: 0.4767 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 157ms/step - accuracy: 0.7694 - loss: 0.4965 - val_accuracy: 0.7492 - val_loss: 0.5121 - learning_rate: 5.0000e-04\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "ok train\n",
      "Entrainement termine => 556.94 secondes\n",
      "\n",
      "Logging de 6 epoques (EarlyStopping peut avoir arrete avant 20)\n",
      "\n",
      "Train - Loss: 0.4755, Accuracy: 0.7729\n",
      "Val   - Loss: 0.4757, Accuracy: 0.7688\n",
      "Test  - Loss: 0.4872, Accuracy: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 20:23:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 20:23:51 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/11/20 20:24:01 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmpup3nkzxt/model, flavor: tensorflow). Fall back to return ['tensorflow==2.16.1', 'cloudpickle==3.1.2']. Set logging level to DEBUG to see the full traceback. \n",
      "\u001b[31m2025/11/20 20:24:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/tracking/_model_registry/utils.py:215: FutureWarning: Filesystem model registry backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri)\n",
      "Registered model 'DL_USE_Dense_softPreProcess' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'DL_USE_Dense_softPreProcess'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarder ok\n",
      "ENTRAINEMENT TERMINE\n",
      "  Test Accuracy : 0.7660\n",
      "  Test F1-Score : 0.7728\n",
      "  Test ROC-AUC  : 0.8475\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"DL_USE_Dense_softPreProcess\"):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    params = {\n",
    "        \"use_dim\": USE_DIM,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"loss\": \"binary_crossentropy\",\n",
    "        \"train_samples\": len(df_train),\n",
    "        \"val_samples\": len(df_val),\n",
    "        \"test_samples\": len(df_test),\n",
    "        \"architecture\": \"USE_Dense\",\n",
    "        \"gpu\": \"Apple M2\",\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Construction du modèle\n",
    "\n",
    "    print(\"Chargement de Universal Sentence Encoder...\")\n",
    "\n",
    "    # Charger USE\n",
    "    use_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "    use_layer = hub.KerasLayer(use_url, trainable=False, name=\"USE\")\n",
    "\n",
    "    # Wrapper pour USE\n",
    "    def use_wrapper(text):\n",
    "        return use_layer(text)\n",
    "\n",
    "    # Construction du modèle avec Functional API\n",
    "    text_input = layers.Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
    "\n",
    "    # USE via Lambda avec output_shape explicite (512 dimensions)\n",
    "    use_output = layers.Lambda(use_wrapper, output_shape=(512,), name=\"use_embedding\")(\n",
    "        text_input\n",
    "    )\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\", name=\"dense_1\")(use_output)\n",
    "    x = layers.Dropout(0.4, name=\"dropout_1\")(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    x = layers.Dropout(0.3, name=\"dropout_2\")(x)\n",
    "\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_3\")(x)\n",
    "    x = layers.Dropout(0.2, name=\"dropout_3\")(x)\n",
    "\n",
    "    output = layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = models.Model(inputs=text_input, outputs=output, name=\"use_dense_model\")\n",
    "\n",
    "    # Compilation\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=AdamW(learning_rate=0.001),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Entraînement\n",
    "    history = model.fit(\n",
    "        data_train,\n",
    "        validation_data=data_val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1,\n",
    "    )\n",
    "    print(\"ok train\")\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "    print(f\"Entrainement termine => {training_time:.2f} secondes\")\n",
    "\n",
    "    actual_epochs = len(history.history[\"loss\"])\n",
    "    mlflow.log_metric(\"actual_epochs\", actual_epochs)\n",
    "    print(\n",
    "        f\"\\nLogging de {actual_epochs} epoques (EarlyStopping peut avoir arrete avant {EPOCHS})\"\n",
    "    )\n",
    "\n",
    "    for epoch in range(actual_epochs):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_accuracy\", history.history[\"accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_accuracy\", history.history[\"val_accuracy\"][epoch], step=epoch\n",
    "        )\n",
    "\n",
    "    train_loss, train_accuracy = model.evaluate(data_train_eval, verbose=0)\n",
    "    val_loss, val_accuracy = model.evaluate(data_val, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", train_loss)\n",
    "    mlflow.log_metric(\"val_loss\", val_loss)\n",
    "    mlflow.log_metric(\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    print(f\"\\nTrain - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val   - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test  - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    y_train_pred_proba = model.predict(data_train_eval, verbose=0).flatten()\n",
    "    y_train_pred = (y_train_pred_proba > 0.5).astype(int)\n",
    "    y_train_true = df_train[\"target\"].values\n",
    "\n",
    "    y_val_pred_proba = model.predict(data_val, verbose=0).flatten()\n",
    "    y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "    y_val_true = df_val[\"target\"].values\n",
    "\n",
    "    y_test_pred_proba = model.predict(data_test, verbose=0).flatten()\n",
    "    y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
    "    y_test_true = df_test[\"target\"].values\n",
    "\n",
    "    def calcul_metriques(y_true, y_pred, y_pred_proba):\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        return precision, recall, f1, roc_auc\n",
    "\n",
    "    train_precision, train_recall, train_f1, train_roc_auc = calcul_metriques(\n",
    "        y_train_true, y_train_pred, y_train_pred_proba\n",
    "    )\n",
    "    val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val_true, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "    test_precision, test_recall, test_f1, test_roc_auc = calcul_metriques(\n",
    "        y_test_true, y_test_pred, y_test_pred_proba\n",
    "    )\n",
    "\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    epochs_range = range(1, actual_epochs + 1)\n",
    "\n",
    "    ax1.plot(\n",
    "        epochs_range,\n",
    "        history.history[\"accuracy\"],\n",
    "        \"b-\",\n",
    "        label=\"Train Accuracy\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax1.plot(\n",
    "        epochs_range,\n",
    "        history.history[\"val_accuracy\"],\n",
    "        \"r:\",\n",
    "        label=\"Val Accuracy\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ax1.set_title(\"Accuracy Train - Val\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"loss\"], \"b-\", label=\"Train Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.plot(\n",
    "        epochs_range, history.history[\"val_loss\"], \"r:\", label=\"Val Loss\", linewidth=2\n",
    "    )\n",
    "    ax2.set_title(\"Loss Train - Val\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_history.png\")\n",
    "    mlflow.log_artifact(\"training_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train_true, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val_true, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test_true, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - Train/Validation/Test\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.savefig(\"roc_curve_comparaison.png\")\n",
    "    mlflow.log_artifact(\"roc_curve_comparaison.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Sauvegarde du modèle\n",
    "\n",
    "    # MLflow\n",
    "    mlflow.tensorflow.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=f\"DL_USE_Dense_softPreProcess\",\n",
    "    )\n",
    "\n",
    "    # Sauvegarde format keras\n",
    "    model_path = \"models/dl_use_sentiment.keras\"\n",
    "    model.save(model_path)\n",
    "    print(\"Sauvegarder ok\")\n",
    "\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"ML_avance\",\n",
    "            \"architecture\": \"use_dense\",\n",
    "            \"dataset\": \"twitter_50K\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"ENTRAINEMENT TERMINE\")\n",
    "print(f\"  Test Accuracy : {test_accuracy:.4f}\")\n",
    "print(f\"  Test F1-Score : {test_f1:.4f}\")\n",
    "print(f\"  Test ROC-AUC  : {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6d2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5693753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p7_use_m2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
