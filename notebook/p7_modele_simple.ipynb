{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93f7f6a",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a103a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import os\n",
    "import mlflow.sklearn\n",
    "import time\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import joblib\n",
    "\n",
    "import optuna\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c450e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/skanderzahi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/skanderzahi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "# from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"maxent_ne_chunker\")  # Souvent requis aussi\n",
    "# nltk.download(\"words\")\n",
    "# nltk.download(\"averaged_perceptron_tagger_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db84295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.7 | packaged by Anaconda, Inc. | (main, Sep  9 2025, 19:54:17) [Clang 17.0.6 ]\n",
      "MLflow version: 3.4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20ad7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 6), (8000, 6), (10000, 6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"dataset/train_50K.csv\")\n",
    "df_val = pd.read_csv(\"dataset/val_50K.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_50K.csv\")\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(\"dataset/train_50K.csv\")\n",
    "# df_val = pd.read_csv(\"dataset/val_50K.csv\")\n",
    "# df_test = pd.read_csv(\"dataset/test_50K.csv\")\n",
    "# df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b6b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(target\n",
       " 1    32046\n",
       " 0    31954\n",
       " Name: count, dtype: int64,\n",
       " target\n",
       " 1    10023\n",
       " 0     9977\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts(), df_test[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28389386",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e573c84",
   "metadata": {},
   "source": [
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7a696b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(target\n",
       " 0    80000\n",
       " 1    80000\n",
       " Name: count, dtype: int64,\n",
       " target\n",
       " 1    20000\n",
       " 0    20000\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"].value_counts(), df_test[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "974ccb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128000, 6), (32000, 6), (40000, 6))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creer un set validation √† partir de train\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train, test_size=0.2, random_state=42, stratify=df_train[\"target\"]\n",
    ")\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2c1f399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©finir le nom de l'exp√©rience\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f63eb0",
   "metadata": {},
   "source": [
    "# ________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb72fae",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291d476",
   "metadata": {},
   "source": [
    "## Preprocess 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e85a5f",
   "metadata": {},
   "source": [
    "Pr√©traitement aggressif : word_tokenize, stopwords, suppression ponctuation, hashtag, mention..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43c7c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess_1\n",
    "def preprocess_1(text):\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    # Convertir en minuscules\n",
    "    text = text.lower()\n",
    "\n",
    "    # Supprimer les URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # Supprimer les mentions et hashtags\n",
    "    text = re.sub(r\"\\@\\w+|\\#\", \"\", text)\n",
    "\n",
    "    # Supprimer la ponctuation et les caract√®res sp√©ciaux\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    # Supprimer les chiffres\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # Tokenisation\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Supprimer les stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Joindre les tokens en une seule cha√Æne\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd313ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_1 train + test\n",
    "df_train[\"text_preprocess_1\"] = df_train[\"text\"].apply(preprocess_1)\n",
    "df_test[\"text_preprocess_1\"] = df_test[\"text\"].apply(preprocess_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2775d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "359c9c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de texte avant/apr√®s preprocess_1:\n",
      "Avant: my eyes burn \n",
      "Apr√®s: eye burn\n"
     ]
    }
   ],
   "source": [
    "# V√©rification d'un √©chantillon\n",
    "print(\"Exemple de texte avant/apr√®s preprocess_1:\")\n",
    "print(\"Avant:\", df_train[\"text\"].iloc[10])\n",
    "print(\"Apr√®s:\", df_train[\"text_preprocess_1\"].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0c57d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tf_idf(X_train_texts, X_test_texts, vectorizer=None):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2), min_df=2, max_df=0.90, max_features=1000\n",
    "    )\n",
    "    X_train = vectorizer.fit_transform(X_train_texts)\n",
    "    X_test = vectorizer.transform(X_test_texts)\n",
    "    return X_train, X_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cae7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, vectorizer = vectorize_tf_idf(\n",
    "    df_train[\"text_preprocess_1\"], df_test[\"text_preprocess_1\"]\n",
    ")\n",
    "y_train = df_train[\"target\"]\n",
    "y_test = df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f75fb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_metriques(y_true, y_pred, y_pred_proba):\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "\n",
    "    return accuracy, precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8945a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mlflow(run_name, preprocess, X_train, X_test, y_train, y_test, vectorizer):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # Log des param√®tres\n",
    "\n",
    "        # mlflow.log_param(\"model_type\", \"LogisticRegression\")  # Type de mod√®le\n",
    "        # mlflow.log_param(\"vectorizer\", \"TF-IDF\")  # Type de vectoriseur\n",
    "        # mlflow.log_param(\"min_df\", 2)  # Seuil de fr√©quence minimale\n",
    "        # mlflow.log_param(\"max_df\", 0.90)  # Seuil de fr√©quence maximale\n",
    "        # mlflow.log_param(\"max_features\", 1000)  # Nombre maximum de caract√©ristiques\n",
    "        # mlflow.log_param(\"ngram_range\", \"(1, 2)\")  # Plage de n-grammes\n",
    "        # mlflow.log_param(\"preprocessing\", preprocess)  # M√©thode de pr√©traitement\n",
    "        # mlflow.log_param(\"random_state\", 42)\n",
    "        # mlflow.log_param(\"max_iter\", 1000)\n",
    "\n",
    "        params = {\n",
    "            \"model_type\": \"LogisticRegression\",\n",
    "            \"vectorizer\": \"TF-IDF\",\n",
    "            \"min_df\": vectorizer.min_df,\n",
    "            \"max_df\": vectorizer.max_df,\n",
    "            \"max_features\": vectorizer.max_features,\n",
    "            \"ngram_range\": str(vectorizer.ngram_range),\n",
    "            \"preprocessing\": preprocess,\n",
    "            \"random_state\": 42,\n",
    "            \"max_iter\": 1000,\n",
    "            \"train_samples\": len(y_train),\n",
    "            \"test_samples\": len(y_test),\n",
    "        }\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Mesurer le temps d'ex√©cution\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Construction de la r√©gression logistique\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "\n",
    "        # Pr√©dire les probabilit√©s pour les ensembles d'entra√Ænement et de test\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Calcul des m√©triques\n",
    "        train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = (\n",
    "            calcul_metriques(y_train, y_train_pred, y_train_pred_proba)\n",
    "        )\n",
    "        test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = (\n",
    "            calcul_metriques(y_test, y_test_pred, y_test_pred_proba)\n",
    "        )\n",
    "\n",
    "        # Affichage des m√©triques train et test\n",
    "        print(\n",
    "            f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\"\n",
    "        )\n",
    "        print(f\"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "        print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "        print(f\"Train ROC AUC: {train_roc_auc:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "        # Train\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"train_f1\", train_f1)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # Test\n",
    "        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "        mlflow.log_metric(\"test_precision\", test_precision)\n",
    "        mlflow.log_metric(\"test_recall\", test_recall)\n",
    "        mlflow.log_metric(\"test_f1\", test_f1)\n",
    "        mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "        # M√©triques d'overfitting (gap train-test)\n",
    "        mlflow.log_metric(\"train_test_accuracy_gap\", train_accuracy - test_accuracy)\n",
    "        mlflow.log_metric(\"train_test_f1_gap\", train_f1 - test_f1)\n",
    "\n",
    "        # Roc AUC train/test\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "        for y_true, y_proba, label, color in [\n",
    "            (y_train, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "            (y_test, y_test_pred_proba, \"Test\", \"red\"),\n",
    "        ]:\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "            auc_score = roc_auc_score(y_true, y_proba)\n",
    "            plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curves - Train/Test\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.savefig(\"roc_curve.png\")\n",
    "        mlflow.log_artifact(\"roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Sauvegarde dans MLflow\n",
    "        mlflow.sklearn.log_model(model, \"logistic_regression_model\")\n",
    "        mlflow.sklearn.log_model(vectorizer, \"tfidf_vectorizer\")\n",
    "        print(\"\\nMod√®le et vectorizer sauvegard√©s dans MLflow\")\n",
    "\n",
    "        # Sauvegarde locale\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "        # Sauvegarder avec joblib\n",
    "        model_path = f\"models/{run_name}_model.joblib\"\n",
    "        joblib.dump(\n",
    "            model, model_path, compress=3\n",
    "        )  # compress=3 pour compression optimale\n",
    "        mlflow.log_artifact(model_path)\n",
    "        print(f\"Mod√®le sauvegard√© (joblib) : {model_path}\")\n",
    "\n",
    "        vectorizer_path = f\"models/{run_name}_vectorizer.joblib\"\n",
    "        joblib.dump(vectorizer, vectorizer_path, compress=3)\n",
    "        mlflow.log_artifact(vectorizer_path)\n",
    "        print(f\"Vectorizer sauvegard√© (joblib) : {vectorizer_path}\")\n",
    "\n",
    "        # Log de la figure ROC dans MLflow\n",
    "        mlflow.log_artifact(\"roc_curve.png\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Affichage du temps d'entra√Ænement\n",
    "        print(f\"Training time (seconds): {training_time:.2f}\")\n",
    "\n",
    "        mlflow.set_tags(\n",
    "            {\n",
    "                \"model_type\": \"ML_classique\",\n",
    "                \"architecture\": \"logistic_regression\",\n",
    "                \"vectorization\": \"tfidf\",\n",
    "                \"dataset\": \"twitter_50K\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Affichage du rapport de classification test\n",
    "        print(\"\\nClassification Report Test :\")\n",
    "        print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b652d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7539, Test Accuracy: 0.7402\n",
      "Train Precision: 0.7405, Test Precision: 0.7289\n",
      "Train Recall: 0.7829, Test Recall: 0.7668\n",
      "Train F1 Score: 0.7611, Test F1 Score: 0.7474\n",
      "Train ROC AUC: 0.8349, Test ROC AUC: 0.8195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 16:21:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/11/20 16:21:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/11/20 16:21:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 16:21:58 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "\u001b[31m2025/11/20 16:22:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mod√®le et vectorizer sauvegard√©s dans MLflow\n",
      "Mod√®le sauvegard√© (joblib) : models/lr_TFIDF_preprocess_1_wordTokenize_lemmatization_model.joblib\n",
      "Vectorizer sauvegard√© (joblib) : models/lr_TFIDF_preprocess_1_wordTokenize_lemmatization_vectorizer.joblib\n",
      "Training time (seconds): 0.08\n",
      "\n",
      "Classification Report Test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73      9977\n",
      "           1       0.73      0.77      0.75     10023\n",
      "\n",
      "    accuracy                           0.74     20000\n",
      "   macro avg       0.74      0.74      0.74     20000\n",
      "weighted avg       0.74      0.74      0.74     20000\n",
      "\n",
      "üèÉ View run lr_TFIDF_preprocess_1_wordTokenize_lemmatization at: http://127.0.0.1:5000/#/experiments/379503310426968982/runs/6ee2101689a54cc2a6d3624e05e76f74\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/379503310426968982\n"
     ]
    }
   ],
   "source": [
    "process_mlflow(\n",
    "    run_name=\"lr_TFIDF_preprocess_1_wordTokenize_lemmatization\",\n",
    "    preprocess=\"preprocess_1\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    vectorizer=vectorizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97d373",
   "metadata": {},
   "source": [
    "## preprocess 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0b10f",
   "metadata": {},
   "source": [
    "Twitter_tokenize, lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d094a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetTokenize(text):\n",
    "    tweet_tokenizer = TweetTokenizer(\n",
    "        preserve_case=False,  # uniformisation en minuscules\n",
    "        reduce_len=True,  # r√©duit les r√©p√©titions de caract√®res\n",
    "        strip_handles=False,  # conserve les @mentions\n",
    "    )\n",
    "    tokens = tweet_tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "82eafe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_2(text):\n",
    "\n",
    "    # Supprimer les URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # Supprimer les chiffres\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # Supprimer les mentions et hashtags\n",
    "    text = re.sub(r\"\\@\\w+|\\#\", \"\", text)\n",
    "\n",
    "    # Supprimer mots d'1 lettre\n",
    "    text = re.sub(r\"\\b[a-z]\\b\", \"\", text)\n",
    "\n",
    "    # Tokenisation\n",
    "    tokens = tweetTokenize(text)\n",
    "\n",
    "    # Lemmatisation\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed9b8dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 9), (8000, 7), (10000, 9))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diviser par deux le dataset pour tester plus rapidement les mod√®les\n",
    "df_train = df_train.sample(frac=0.5, random_state=42)\n",
    "df_test = df_test.sample(frac=0.5, random_state=42)\n",
    "df_val = df_val.sample(frac=0.5, random_state=42)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8094b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_2 train + val + test\n",
    "df_train[\"text_preprocess_2\"] = df_train[\"text\"].apply(preprocess_2)\n",
    "df_val[\"text_preprocess_2\"] = df_val[\"text\"].apply(preprocess_2)\n",
    "df_test[\"text_preprocess_2\"] = df_test[\"text\"].apply(preprocess_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a49a5349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33042    very excited for new moon trailer although i w...\n",
       "7209               rediscovering my love for missy higgins\n",
       "24367    aww . babe juss called juss cuz he lovez me . ...\n",
       "19599    brother & million sister get better every time...\n",
       "31465       going to go see terri , jimmy , & jennifer ...\n",
       "                               ...                        \n",
       "21112    i ' sick and tired of twitter because of so ma...\n",
       "1006     brief and sock . and of course phoebe ' hoodie...\n",
       "51563    final cut crashed and deleted all my captured ...\n",
       "42088                    yeah mate im coming in at about :\n",
       "720                when do we get to hear body control ? ?\n",
       "Name: text_preprocess_2, Length: 32000, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"text_preprocess_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "439ae2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "63995    1\n",
       "63996    1\n",
       "63997    1\n",
       "63998    1\n",
       "63999    1\n",
       "Name: target, Length: 64000, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb5fbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"target\"]\n",
    "y_test = df_test[\"target\"]\n",
    "y_val = df_val[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bf60ad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de texte avant/apr√®s preprocess_2:\n",
      "Avant: Good afternoon!  Last night, I had the company of Shermaine through text messaging. Lovely friend I've got to known recently. \n",
      "Apr√®s: good afternoon ! last night , i had the company of shermaine through text messaging . lovely friend i've got to known recently .\n"
     ]
    }
   ],
   "source": [
    "# V√©rification d'un √©chantillon\n",
    "print(\"Exemple de texte avant/apr√®s preprocess_2:\")\n",
    "print(\"Avant:\", df_train[\"text\"].iloc[0])\n",
    "print(\"Apr√®s:\", df_train[\"text_preprocess_2\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f63ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation TF-IDF\n",
    "X_train, X_test, vectorizer = vectorize_tf_idf(\n",
    "    df_train[\"text_preprocess_2\"], df_test[\"text_preprocess_2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "98bd0621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64000, 75636)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba8007",
   "metadata": {},
   "source": [
    "## Mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1cef7e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 16:32:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7671, Test Accuracy: 0.7526\n",
      "Train Precision: 0.7619, Test Precision: 0.7494\n",
      "Train Recall: 0.7780, Test Recall: 0.7607\n",
      "Train F1 Score: 0.7699, Test F1 Score: 0.7550\n",
      "Train ROC AUC: 0.8468, Test ROC AUC: 0.8338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/20 16:32:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/11/20 16:32:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 16:32:30 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "\u001b[31m2025/11/20 16:32:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mod√®le et vectorizer sauvegard√©s dans MLflow\n",
      "Mod√®le sauvegard√© (joblib) : models/lr_TFIDF_preprocess_2_tweetTokenize_lemmatization__model.joblib\n",
      "Vectorizer sauvegard√© (joblib) : models/lr_TFIDF_preprocess_2_tweetTokenize_lemmatization__vectorizer.joblib\n",
      "Training time (seconds): 0.06\n",
      "\n",
      "Classification Report Test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      9977\n",
      "           1       0.75      0.76      0.76     10023\n",
      "\n",
      "    accuracy                           0.75     20000\n",
      "   macro avg       0.75      0.75      0.75     20000\n",
      "weighted avg       0.75      0.75      0.75     20000\n",
      "\n",
      "üèÉ View run lr_TFIDF_preprocess_2_tweetTokenize_lemmatization_ at: http://127.0.0.1:5000/#/experiments/379503310426968982/runs/1fbf865d5ad345769141a099f372999e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/379503310426968982\n"
     ]
    }
   ],
   "source": [
    "process_mlflow(\n",
    "    run_name=\"lr_TFIDF_preprocess_2_tweetTokenize_lemmatization_\",\n",
    "    preprocess=\"preprocess_2\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    vectorizer=vectorizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant: I can't believe you won't do it. I'm so happy! y'all should've seen it, cats\n",
      "Avant: ['i', \"can't\", 'believe', 'you', \"won't\", 'do', 'it', '.', \"i'm\", 'so', 'happy', '!', \"y'all\", \"should've\", 'seen', 'it', ',', 'cats']\n",
      "Apr√®s: ['i', \"can't\", 'believe', 'you', \"won't\", 'do', 'it', '.', \"i'm\", 'so', 'happy', '!', \"y'all\", \"should've\", 'seen', 'it', ',', 'cat']\n",
      "Apr√®s avec POS: ['i', \"can't\", 'believe', 'you', \"won't\", 'do', 'it', '.', \"i'm\", 'so', 'happy', '!', \"y'all\", \"should've\", 'see', 'it', ',', 'cat']\n",
      "Apr√®s avec stemming: ['i', \"can't\", 'believ', 'you', \"won't\", 'do', 'it', '.', \"i'm\", 'so', 'happi', '!', \"y'all\", \"should'v\", 'seen', 'it', ',', 'cat']\n"
     ]
    }
   ],
   "source": [
    "test_text = (\n",
    "    \"I can't believe you won't do it. I'm so happy! y'all should've seen it, cats\"\n",
    ")\n",
    "tokens = tweetTokenize(test_text)\n",
    "print(\"Avant:\", test_text)\n",
    "print(\"Avant:\", tokens)\n",
    "print(\"Apr√®s:\", [lemmatizer.lemmatize(token) for token in tokens])\n",
    "tagged = pos_tag(tokens)\n",
    "lemmas_pos = [lemmatizer.lemmatize(t, tb_to_wn(tag)) for t, tag in tagged]\n",
    "print(\"Apr√®s avec POS:\", lemmas_pos)\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(token) for token in tokens]\n",
    "print(\"Apr√®s avec stemming:\", stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), (\"can't\", 'VBP'), ('believe', 'VB'), ('you', 'PRP'), (\"won't\", 'WDT'), ('do', 'VB'), ('it', 'PRP'), ('.', '.'), (\"I'm\", 'NNP'), ('so', 'IN'), ('happy', 'JJ'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "# from nltk.tokenize import TweetTokenizer\n",
    "# from nltk import pos_tag\n",
    "\n",
    "# tknzr = TweetTokenizer()\n",
    "# tokens = tknzr.tokenize(\"I can't believe you won't do it. I'm so happy!\")\n",
    "# tags = pos_tag(tokens)\n",
    "# print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac0987",
   "metadata": {},
   "source": [
    "## Preprocess 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdb5f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_3(text):\n",
    "\n",
    "    # Supprimer les URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # Supprimer les chiffres\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # Supprimer les mentions et hashtags\n",
    "    text = re.sub(r\"\\@\\w+|\\#\", \"\", text)\n",
    "\n",
    "    # Tokenisation\n",
    "    tokens = tweetTokenize(text)\n",
    "\n",
    "    # Stemmerisation\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8e08965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_3 train + test\n",
    "df_train[\"text_preprocess_3\"] = df_train[\"text\"].apply(preprocess_3)\n",
    "df_test[\"text_preprocess_3\"] = df_test[\"text\"].apply(preprocess_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8022fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de texte avant/apr√®s preprocess_1:\n",
      "Avant: Wow. Just found out that Ronald Takaki committed suicide this week.  RIP, Professor.  http://bit.ly/DbuT1\n",
      "Apr√®s: wow found ronald takaki committed suicide week rip professor\n"
     ]
    }
   ],
   "source": [
    "# V√©rification d'un √©chantillon\n",
    "print(\"Exemple de texte avant/apr√®s preprocess_1:\")\n",
    "print(\"Avant:\", df_train[\"text\"].iloc[100])\n",
    "print(\"Apr√®s:\", df_train[\"text_preprocess_1\"].iloc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b5b5e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetorisation TF-IDF\n",
    "X_train, X_test, vectorizer = vectorize_tf_idf(\n",
    "    df_train[\"text_preprocess_3\"], df_test[\"text_preprocess_3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc951f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7702, Test Accuracy: 0.7547\n",
      "Train Precision: 0.7644, Test Precision: 0.7502\n",
      "Train Recall: 0.7823, Test Recall: 0.7653\n",
      "Train F1 Score: 0.7732, Test F1 Score: 0.7577\n",
      "Train ROC AUC: 0.8500, Test ROC AUC: 0.8366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/20 16:26:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/11/20 16:26:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/11/20 16:26:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/20 16:26:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "\u001b[31m2025/11/20 16:26:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mod√®le et vectorizer sauvegard√©s dans MLflow\n",
      "Mod√®le sauvegard√© (joblib) : models/lr_TFIDF_preprocess_3_tweetTokenize_stemming_model.joblib\n",
      "Vectorizer sauvegard√© (joblib) : models/lr_TFIDF_preprocess_3_tweetTokenize_stemming_vectorizer.joblib\n",
      "Training time (seconds): 0.06\n",
      "\n",
      "Classification Report Test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      9977\n",
      "           1       0.75      0.77      0.76     10023\n",
      "\n",
      "    accuracy                           0.75     20000\n",
      "   macro avg       0.75      0.75      0.75     20000\n",
      "weighted avg       0.75      0.75      0.75     20000\n",
      "\n",
      "üèÉ View run lr_TFIDF_preprocess_3_tweetTokenize_stemming at: http://127.0.0.1:5000/#/experiments/379503310426968982/runs/12e52b2ef95b402fa85ec88bd9cce184\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/379503310426968982\n"
     ]
    }
   ],
   "source": [
    "process_mlflow(\n",
    "    run_name=\"lr_TFIDF_preprocess_3_tweetTokenize_stemming\",\n",
    "    preprocess=\"preprocess_3\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    vectorizer=vectorizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d788b",
   "metadata": {},
   "source": [
    "=> preprocess 2 et 3 presque identiques cependant preprocess 2 est plus rapide en terme d'execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a045da3",
   "metadata": {},
   "source": [
    "## Hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1f538916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64000, 6), (16000, 6), (20000, 6))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diviser par deux le dataset pour tester plus rapidement les mod√®les\n",
    "df_train = df_train.sample(frac=0.5, random_state=42)\n",
    "df_test = df_test.sample(frac=0.5, random_state=42)\n",
    "df_val = df_val.sample(frac=0.5, random_state=42)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv(\"train_100K.csv\", index=False)\n",
    "# df_val.to_csv(\"val_100K.csv\", index=False)\n",
    "# df_test.to_csv(\"test_100K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def try_param_lr(X_train, X_test, y_train, y_test, model, param_grid):\n",
    "    \n",
    "#     from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#     model = LogisticRegression(random_state=42)\n",
    "\n",
    "#     grid_search = GridSearchCV(\n",
    "#         estimator=model,\n",
    "#         param_grid=param_grid,\n",
    "#         scoring=\"accuracy\",\n",
    "#         cv=5,\n",
    "#         n_jobs=-1,\n",
    "#         verbose=2,\n",
    "#     )\n",
    "\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "#     best_model = grid_search.best_estimator_\n",
    "\n",
    "#     # Pr√©dire les probabilit√©s pour les ensembles d'entra√Ænement et de test\n",
    "#     y_train_pred = best_model.predict(X_train)\n",
    "#     y_train_pred_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "#     y_test_pred = best_model.predict(X_test)\n",
    "#     y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#     # Calcul des m√©triques\n",
    "#     train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = (\n",
    "#         calcul_metriques(y_train, y_train_pred, y_train_pred_proba)\n",
    "#     )\n",
    "#     test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = (\n",
    "#         calcul_metriques(y_test, y_test_pred, y_test_pred_proba)\n",
    "#     )\n",
    "\n",
    "#     # Affichage des m√©triques train et test\n",
    "#     print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "#     print(\n",
    "#         f\"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\"\n",
    "#     )\n",
    "#     print(f\"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "#     print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "#     print(f\"Train ROC AUC: {train_roc_auc:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "}\n",
    "model = LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16e1addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_params_mlflow(\n",
    "    run_name, X_train, X_test, X_val, y_train, y_test, y_val, param_grid\n",
    "):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            scoring=\"accuracy\",\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=2,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "\n",
    "        print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "        for param_name, param_value in grid_search.best_params_.items():\n",
    "            mlflow.log_param(f\"best_{param_name}\", param_value)\n",
    "\n",
    "        mlflow.log_metric(\"best_cv_score\", grid_search.best_score_)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Pr√©dictions\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_train_pred_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "        y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Calcul des m√©triques\n",
    "        train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = (\n",
    "            calcul_metriques(y_train, y_train_pred, y_train_pred_proba)\n",
    "        )\n",
    "        val_accuracy, val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "            y_val, y_val_pred, y_val_pred_proba\n",
    "        )\n",
    "        test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = (\n",
    "            calcul_metriques(y_test, y_test_pred, y_test_pred_proba)\n",
    "        )\n",
    "        # Affichage des m√©triques train et test\n",
    "        print(\n",
    "            f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\"\n",
    "        )\n",
    "        print(f\"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "        print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "        print(f\"Train ROC AUC: {train_roc_auc:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "        # Log des params√®tres\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_param(\"model_type\", \"LR_GS\")\n",
    "        mlflow.log_param(\"cv_folds\", 5)\n",
    "        mlflow.log_param(\"scoring\", \"accuracy\")\n",
    "        mlflow.log_param(\"param_grid\", str(param_grid))\n",
    "\n",
    "        # M√©triques d'entra√Ænement\n",
    "        mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"train_f1\", train_f1)\n",
    "        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "        # M√©triques de validation\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "        mlflow.log_metric(\"val_f1\", val_f1)\n",
    "        mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "        # M√©triques de test\n",
    "        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "        mlflow.log_metric(\"test_precision\", test_precision)\n",
    "        mlflow.log_metric(\"test_recall\", test_recall)\n",
    "        mlflow.log_metric(\"test_f1\", test_f1)\n",
    "        mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "        mlflow.log_metric(\"best_cv_score\", grid_search.best_score_)\n",
    "\n",
    "        # Overfitting check\n",
    "        mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "        mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "        mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "        mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "        # Mod√®le\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            name=\"model\",\n",
    "            registered_model_name=\"LogisticRegression_Tweets_Sentiment\",\n",
    "        )\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color=\"blue\", label=f\"ROC curve (AUC = {test_roc_auc:.4f})\")\n",
    "        plt.plot([0, 1], [0, 1], color=\"red\", linestyle=\"--\", label=\"Random\")\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.savefig(\"roc_curve.png\")\n",
    "        mlflow.log_artifact(\"roc_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Affichage du rapport de classification test\n",
    "        print(\"\\nClassification Report Test :\")\n",
    "        print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "        mlflow.sklearn.log_model(best_model, \"best_lr_model\")\n",
    "\n",
    "        cv_results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "        cv_results_df.to_csv(\"cv_results.csv\", index=False)\n",
    "        mlflow.log_artifact(\"cv_results.csv\")\n",
    "\n",
    "        return best_model, grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f970214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tf_idf(X_train_texts, X_test_texts, X_val_texts, vectorizer=None):\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_df=0.90)\n",
    "    X_train = vectorizer.fit_transform(X_train_texts)\n",
    "    X_test = vectorizer.transform(X_test_texts)\n",
    "    X_val = vectorizer.transform(X_val_texts)\n",
    "    return X_train, X_test, X_val, vectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e334b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, vectorizer = vectorize_tf_idf(\n",
    "    df_train[\"text_preprocess_1\"],\n",
    "    df_test[\"text_preprocess_1\"],\n",
    "    df_val[\"text_preprocess_1\"],\n",
    ")\n",
    "\n",
    "\n",
    "y_train = df_train[\"target\"]\n",
    "y_test = df_test[\"target\"]\n",
    "y_val = df_val[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae566dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    # \"penalty\": [\"l2\", \"l1\"],\n",
    "    # \"solver\": [\"liblinear\", \"saga\"],\n",
    "}\n",
    "\n",
    "best_model, grid = process_params_mlflow(\n",
    "    run_name=\"GridSearch_LogReg_TF-IDF\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    param_grid=param_grid,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "03ab655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/16 11:49:13 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/16 11:49:13 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.3s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.4s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/16 11:49:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Train Accuracy: 0.8420, Test Accuracy: 0.7651\n",
      "Train Precision: 0.8332, Test Precision: 0.7603\n",
      "Train Recall: 0.8557, Test Recall: 0.7761\n",
      "Train F1 Score: 0.8443, Test F1 Score: 0.7681\n",
      "Train ROC AUC: 0.9176, Test ROC AUC: 0.8453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/16 11:49:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'LogisticRegression_Tweets_Sentiment' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'LogisticRegression_Tweets_Sentiment'.\n",
      "2025/10/16 11:49:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report Test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      9977\n",
      "           1       0.76      0.78      0.77     10023\n",
      "\n",
      "    accuracy                           0.77     20000\n",
      "   macro avg       0.77      0.77      0.77     20000\n",
      "weighted avg       0.77      0.77      0.77     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/16 11:49:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/10/16 11:49:22 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/16 11:49:22 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": [1],\n",
    "    \"penalty\": [\"l2\", \"l1\"],\n",
    "    # \"solver\": [\"liblinear\", \"saga\"],\n",
    "}\n",
    "\n",
    "best_model, grid = process_params_mlflow(\n",
    "    run_name=\"GridSearch_LogReg_TF-IDF\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    param_grid=param_grid,  # True si tu as un Model Registry\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "494108e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/16 11:50:43 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/10/16 11:50:43 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .....................C=0.5, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .....................C=0.5, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .....................C=0.5, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .....................C=0.5, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV] END .....................C=0.5, penalty=l2, solver=saga; total time=   0.3s\n",
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Train Accuracy: 0.8420, Test Accuracy: 0.7651\n",
      "Train Precision: 0.8332, Test Precision: 0.7603\n",
      "Train Recall: 0.8557, Test Recall: 0.7761\n",
      "Train F1 Score: 0.8443, Test F1 Score: 0.7681\n",
      "Train ROC AUC: 0.9176, Test ROC AUC: 0.8453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/16 11:50:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/16 11:50:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'LogisticRegression_Tweets_Sentiment' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'LogisticRegression_Tweets_Sentiment'.\n",
      "2025/10/16 11:50:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report Test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      9977\n",
      "           1       0.76      0.78      0.77     10023\n",
      "\n",
      "    accuracy                           0.77     20000\n",
      "   macro avg       0.77      0.77      0.77     20000\n",
      "weighted avg       0.77      0.77      0.77     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/16 11:50:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/10/16 11:50:49 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/16 11:50:49 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": [1, 0.5],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"saga\"],\n",
    "}\n",
    "\n",
    "best_model, grid = process_params_mlflow(\n",
    "    run_name=\"GridSearch_LogReg_TF-IDF\",\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    param_grid=param_grid,  # True si tu as un Model Registry\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e12e6f",
   "metadata": {},
   "source": [
    "## Optuna => tfidf + RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e69e08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©finir le nom de l'exp√©rience\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86ff0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/glove_test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9d3fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64000, 6), (16000, 6), (20000, 6))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "499ffd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 6), (8000, 6), (10000, 6))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sample(frac=0.5, random_state=42)\n",
    "df_test = df_test.sample(frac=0.5, random_state=42)\n",
    "df_val = df_val.sample(frac=0.5, random_state=42)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5afc51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_2 train + val + test\n",
    "X_train = df_train[\"text\"].apply(preprocess_2)\n",
    "X_val = df_val[\"text\"].apply(preprocess_2)\n",
    "X_test = df_test[\"text\"].apply(preprocess_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f132c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"target\"]\n",
    "y_val = df_val[\"target\"]\n",
    "y_test = df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f5a3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # r√©gulation\n",
    "    penalty = \"l2\"  # trial.suggest_categorical(\"classifier_penalty\", [\"l1\", \"l2\"])\n",
    "\n",
    "    solver = \"liblinear\"  # (  trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\", \"lbfgs\"]) )\n",
    "\n",
    "    # if penalty == \"l1\" and solver == \"lbfgs\":  # Si l1 stop trial\n",
    "    #     raise optuna.TrialPruned()\n",
    "\n",
    "    # Param√®tres TF-IDF\n",
    "    ngram_max = trial.suggest_int(\"ngram_max\", 2, 3)\n",
    "    min_df = 5  # trial.suggest_int(\"min_df\", 1, 2)\n",
    "    max_df = 0.95  # trial.suggest_float(\"max_df\", 0.8, 1.0)\n",
    "    max_features = trial.suggest_int(\"max_features\", 4000, 10000, step=2000)\n",
    "\n",
    "    # Param√®tre C (force de la r√©gularisation)\n",
    "    C = trial.suggest_float(\"C\", 1e-3, 1e2, log=True)\n",
    "\n",
    "    # Param√®tre max_iter\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 1000, step=100)\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"tfidf\",\n",
    "                TfidfVectorizer(\n",
    "                    ngram_range=(1, ngram_max),\n",
    "                    min_df=min_df,\n",
    "                    max_df=max_df,\n",
    "                    max_features=max_features,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    C=C,\n",
    "                    penalty=penalty,\n",
    "                    solver=solver,\n",
    "                    max_iter=max_iter,\n",
    "                    random_state=42,\n",
    "                    n_jobs=1,  # 1 job car Optuna parall√©lise d√©j√†\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Run MLflow\n",
    "    with mlflow.start_run(\n",
    "        nested=True\n",
    "    ):  # nested=True creer un run enfant pour cet essai (run imbriqu√©s)\n",
    "\n",
    "        # Logger les param√®tres\n",
    "        params = {\n",
    "            \"trial_number\": trial.number,\n",
    "            \"ngram_range\": f\"(1, {ngram_max})\",\n",
    "            \"min_df\": min_df,\n",
    "            \"max_df\": max_df,\n",
    "            \"max_features\": max_features,\n",
    "            \"C\": C,\n",
    "            \"penalty\": penalty,\n",
    "            \"solver\": solver,\n",
    "            \"max_iter\": max_iter,\n",
    "        }\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        cv_scores = cross_val_score(\n",
    "            pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=3,\n",
    "            scoring=\"accuracy\",\n",
    "            n_jobs=1,  # Pas de parall√©lisation (conflit avec Optuna)\n",
    "        )\n",
    "        # Score mean\n",
    "        mean_cv_score = cv_scores.mean()\n",
    "        std_cv_scores = cv_scores.std()\n",
    "\n",
    "        # Log des metriques\n",
    "        mlflow.log_metric(\"cv_accuracy_mean\", mean_cv_score)\n",
    "        mlflow.log_metric(\"cv_accuracy_std\", std_cv_scores)\n",
    "\n",
    "        # Optuna optimise le score moyen\n",
    "        score = mean_cv_score\n",
    "\n",
    "        mlflow.set_tags(\n",
    "            {\n",
    "                \"trial_number\": trial.number,\n",
    "                \"optimizer\": \"optuna\",\n",
    "                \"model\": \"tfidf_logreg\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fba5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:32:20,953] A new study created in RDB with name: optimisation_tfidf_logreg_50K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimisation_tfidf_logreg_50K OK\n"
     ]
    }
   ],
   "source": [
    "# Etude optuna\n",
    "study = optuna.create_study(\n",
    "    study_name=\"optimisation_tfidf_logreg_50K\",\n",
    "    direction=\"maximize\",  # Maxsimizer accuracy\n",
    "    storage=\"sqlite:///optuna_tfidf.db\",\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5\n",
    "    ),  # => Arr√™te les trials peu prometteurs\n",
    ")\n",
    "print(f\"{study.study_name} OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acc66779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:   4%|‚ñç         | 1/25 [00:01<00:40,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:08,609] Trial 50 finished with value: 0.7488126118175815 and parameters: {'ngram_max': 2, 'max_features': 8000, 'C': 15.520580642188301, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:   8%|‚ñä         | 2/25 [00:04<00:48,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:10,976] Trial 51 finished with value: 0.7659687856768352 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 2.733539316698807, 'max_iter': 400}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  12%|‚ñà‚ñè        | 3/25 [00:06<00:49,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:13,401] Trial 52 finished with value: 0.7690313042380842 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.9265532079201195, 'max_iter': 400}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  16%|‚ñà‚ñå        | 4/25 [00:08<00:49,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:15,897] Trial 53 finished with value: 0.7630937641861734 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 5.635187731864964, 'max_iter': 300}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  20%|‚ñà‚ñà        | 5/25 [00:11<00:47,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:18,350] Trial 54 finished with value: 0.7670000679064191 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.219291779551437, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:13<00:44,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:20,665] Trial 55 finished with value: 0.7626250288341531 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 0.3743109943192454, 'max_iter': 400}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:16<00:42,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:23,103] Trial 56 finished with value: 0.7671875737663433 and parameters: {'ngram_max': 3, 'max_features': 6000, 'C': 0.7591592954298905, 'max_iter': 600}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:18<00:41,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:25,573] Trial 57 finished with value: 0.760875030783921 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 6.659031575940987, 'max_iter': 400}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:21<00:38,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:28,044] Trial 58 finished with value: 0.7690625620508894 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.6723265887937984, 'max_iter': 200}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:23<00:37,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:30,593] Trial 59 finished with value: 0.7636563520806439 and parameters: {'ngram_max': 3, 'max_features': 4000, 'C': 3.147816446397338, 'max_iter': 200}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:26<00:34,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:33,107] Trial 60 finished with value: 0.7467187983349456 and parameters: {'ngram_max': 3, 'max_features': 10000, 'C': 0.09115360482823955, 'max_iter': 200}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:28<00:32,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:35,573] Trial 61 finished with value: 0.7690313130274214 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.6459961630015216, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:31<00:29,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:37,977] Trial 62 finished with value: 0.767531336462724 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.0613377203930843, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:33<00:26,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:40,407] Trial 63 finished with value: 0.7665625727885296 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 0.6317773718699348, 'max_iter': 600}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:35<00:24,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:42,891] Trial 64 finished with value: 0.7690937993552412 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.9203344603918628, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:38<00:22,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:45,659] Trial 65 finished with value: 0.7596875210156715 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 0.27481300416122006, 'max_iter': 600}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:41<00:20,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:48,220] Trial 66 finished with value: 0.7530000424876558 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 11.208151487991094, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:43<00:18,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:50,882] Trial 67 finished with value: 0.7664688169287884 and parameters: {'ngram_max': 3, 'max_features': 6000, 'C': 2.6557211410134762, 'max_iter': 300}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:46<00:15,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:53,684] Trial 68 finished with value: 0.7680625698616804 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.451507714183546, 'max_iter': 700}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:49<00:13,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:56,323] Trial 69 finished with value: 0.7653437817692423 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 3.576595620720848, 'max_iter': 900}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:52<00:10,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:38:58,987] Trial 70 finished with value: 0.7672188608769392 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 0.9796030910390552, 'max_iter': 100}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:54<00:07,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:39:01,365] Trial 71 finished with value: 0.7680312856808635 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 2.314475210588771, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:56<00:05,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:39:03,702] Trial 72 finished with value: 0.7690937993552412 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 1.922200577315103, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:59<00:02,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:39:06,060] Trial 73 finished with value: 0.7641250434859782 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 0.4730516018401285, 'max_iter': 400}. Best is trial 21 with value: 0.7690938022850203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.769094: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 16:39:08,420] Trial 74 finished with value: 0.7644687798143472 and parameters: {'ngram_max': 3, 'max_features': 8000, 'C': 4.689725873527641, 'max_iter': 500}. Best is trial 21 with value: 0.7690938022850203.\n",
      "Trials compl√©t√©s: 75\n",
      "\n",
      "Meilleurs param√®tres: {'ngram_max': 3, 'max_features': 8000, 'C': 1.935474476346391, 'max_iter': 400}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projet_7_env/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod√®le final entra√Æn√© avec best_params\n",
      "Train Accuracy: 0.8417, Test Accuracy: 0.7710\n",
      "Train Precision: 0.8367, Test Precision: 0.7649\n",
      "Train Recall: 0.8498, Test Recall: 0.7794\n",
      "Train F1 Score: 0.8432, Test F1 Score: 0.7721\n",
      "Train ROC AUC: 0.9191, Test ROC AUC: 0.8498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/22 16:39:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/22 16:39:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'tfidf_logreg_optuna'.\n",
      "Created version '1' of model 'tfidf_logreg_optuna'.\n"
     ]
    }
   ],
   "source": [
    "# Optimisation avec Mlflow (run parent)\n",
    "N_TRIALS = 25\n",
    "# Run\n",
    "with mlflow.start_run(run_name=f\"tfidf_LR_with_Optuna_50K\"):\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"n_trials\": N_TRIALS,\n",
    "            \"direction\": \"maximize\",\n",
    "            \"metric\": \"accuracy\",\n",
    "            \"cv_folds\": 3,\n",
    "            \"train_samples\": len(X_train),\n",
    "            \"val_samples\": len(X_val),\n",
    "            \"test_samples\": len(X_test),\n",
    "        }\n",
    "    )\n",
    "    # D√©marrage de l'optimisation\n",
    "    start_time = time.time()\n",
    "\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=N_TRIALS,\n",
    "        n_jobs=1,\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Trials compl√©t√©s: {len(study.trials)}\")\n",
    "\n",
    "    # Meilleurs resultats\n",
    "    best_trial = study.best_trial\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "\n",
    "    print(f\"\\nMeilleurs param√®tres: {best_params}\")\n",
    "\n",
    "    # Logger les meilleurs r√©sultats\n",
    "    mlflow.log_metric(\"best_cv_accuracy\", best_value)\n",
    "    mlflow.log_param(\"best_trial_number\", best_trial.number)\n",
    "    for key, value in best_params.items():\n",
    "        mlflow.log_param(f\"best_{key}\", value)\n",
    "\n",
    "    mlflow.log_metric(\"optimization_time_minutes\", elapsed_time / 60)\n",
    "    mlflow.log_metric(\"total_trials\", len(study.trials))\n",
    "\n",
    "    # Entrainement du mod√®le\n",
    "\n",
    "    # Recr√©er le pipeline avec les meilleurs param√®tres\n",
    "    best_pipeline = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"tfidf\",\n",
    "                TfidfVectorizer(\n",
    "                    ngram_range=(1, best_params[\"ngram_max\"]),\n",
    "                    min_df=5,  # best_params[\"min_df\"],\n",
    "                    max_df=0.95,  # best_params[\"max_df\"],\n",
    "                    max_features=best_params[\"max_features\"],\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    C=best_params[\"C\"],\n",
    "                    penalty=\"l2\",  # best_params[\"classifier_penalty\"],\n",
    "                    solver=\"liblinear\",  # best_params[\"classifier_solver\"],\n",
    "                    max_iter=best_params[\"max_iter\"],\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,  # Tous les CPU pour l'entra√Ænement final\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Entra√Ænement sur train\n",
    "    model = best_pipeline.fit(X_train, y_train)\n",
    "    print(\"Mod√®le final entra√Æn√© avec best_params\")\n",
    "\n",
    "    # Pr√©dictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calcul des m√©triques\n",
    "    train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = (\n",
    "        calcul_metriques(y_train, y_train_pred, y_train_pred_proba)\n",
    "    )\n",
    "    val_accuracy, val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "    test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = (\n",
    "        calcul_metriques(y_test, y_test_pred, y_test_pred_proba)\n",
    "    )\n",
    "\n",
    "    # Affichage des m√©triques train et test\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\n",
    "        f\"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\"\n",
    "    )\n",
    "    print(f\"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"Train ROC AUC: {train_roc_auc:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "    # M√©triques d'entra√Ænement\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # M√©triques de validation\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    # M√©triques de test\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    # Overfitting check\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    # Courbe ROC pour tarin, val,test\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - Train/Validation/Test\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.savefig(\"roc_curve_tfidf.png\")\n",
    "    mlflow.log_artifact(\"roc_curve_tfidf.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Tag Mlflow\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"optuna_tfidf_LR\",\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"dataset\": \"50K\",\n",
    "            \"best_trial\": best_trial.number,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Sauvegarde du mod√®le\n",
    "    mlflow.sklearn.log_model(\n",
    "        best_pipeline,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"tfidf_logreg_optuna\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f75ebbe",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4182db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8221cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = [text.split() for text in df_train[\"text_preprocess_2\"]]\n",
    "val_tokens = [text.split() for text in df_val[\"text_preprocess_2\"]]\n",
    "test_tokens = [text.split() for text in df_test[\"text_preprocess_2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f456926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x31e3e04d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_word2vec = Word2Vec(\n",
    "    sentences=train_tokens,\n",
    "    vector_size=100,  #  vector_size 100 dimensions\n",
    "    window=10,  # contexte\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    seed=42,\n",
    "    epochs=10,\n",
    ")\n",
    "modele_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c2c51c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire: 15339 mots\n",
      "Dimension des embeddings: 100\n"
     ]
    }
   ],
   "source": [
    "# Inspection du modele\n",
    "print(f\"Taille du vocabulaire: {len(modele_word2vec.wv)} mots\")\n",
    "print(f\"Dimension des embeddings: {modele_word2vec.vector_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = modele_word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f328c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14606951,  0.2443309 , -0.16618145, -0.39835092, -0.19266507,\n",
       "        0.6375418 ,  0.3082946 ,  0.69206226, -0.29387406, -0.03315203,\n",
       "        0.1407305 ,  0.6681998 ,  0.13545899, -0.04654643, -0.42492375,\n",
       "       -0.20002839, -0.38407487, -0.18934639, -0.5324323 ,  0.19156584,\n",
       "        0.29691514, -0.03630893,  0.22086535, -0.10622748,  0.27650416,\n",
       "       -0.03590391, -0.6126007 ,  0.01843317, -0.5018946 ,  0.30600595,\n",
       "       -0.25211385, -0.27665663, -0.01966534,  0.24530771, -0.6240829 ,\n",
       "       -0.44110784, -0.16393135, -0.49064624,  0.0424917 ,  0.14280532,\n",
       "        0.25607914,  0.38413715,  0.5295669 , -0.2558547 ,  0.41900137,\n",
       "       -0.08833858,  0.22970605,  0.3063318 ,  0.5627364 , -0.2193433 ,\n",
       "       -0.07937307, -0.54909104,  0.45931447,  0.0348423 ,  0.01552992,\n",
       "       -0.22221746,  0.21129425, -0.0902129 , -0.14876099,  0.3967147 ,\n",
       "       -0.14047666,  0.10062578, -0.09225155,  0.24447569,  0.32669288,\n",
       "       -0.13255861,  0.2842013 , -0.16739064, -0.01965655,  0.13848363,\n",
       "        0.007558  , -0.00184423,  0.2556931 , -0.2600897 ,  0.37830907,\n",
       "        0.05521717,  0.08881879,  0.02557017,  0.5836371 , -0.1402662 ,\n",
       "        0.38521838, -0.09836798, -0.15753272,  0.12148993, -0.24163099,\n",
       "        0.4515296 , -0.33849618, -0.03939716, -0.18024161,  0.2547239 ,\n",
       "       -0.24825618,  0.1740657 ,  0.20496187, -0.12833607,  0.09187729,\n",
       "       -0.33331358,  0.21708995,  0.5238858 , -0.49773142,  0.11001468],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = words[\"good\"]\n",
    "vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbd0e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarit√© gensim 0.5542354583740234\n",
      "Intrus entre: good, happy, best, work \n",
      "work\n"
     ]
    }
   ],
   "source": [
    "vec2 = words[\"bad\"]\n",
    "# similarit√© gensim\n",
    "similarite = words.similarity(\"good\", \"bad\")\n",
    "print(f\"Similarit√© gensim {similarite}\")\n",
    "# intrus\n",
    "print(\"Intrus entre: good, happy, best, work \")\n",
    "print(words.doesnt_match([\"good\", \"happy\", \"best\", \"work\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27ebc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer les embeddings\n",
    "def create_embeddings(data_tokens):\n",
    "    X_data_w2v = []\n",
    "    for tokens in data_tokens:\n",
    "        word_vectors = []\n",
    "        for token in tokens:\n",
    "            if token in modele_word2vec.wv:\n",
    "                vector = modele_word2vec.wv[token]\n",
    "                word_vectors.append(vector)\n",
    "        if len(word_vectors) > 0:\n",
    "            tweet_embedding = np.mean(word_vectors, axis=0)\n",
    "        else:\n",
    "            tweet_embedding = np.zeros(100)  # Si aucun mot connu vecteur 0\n",
    "        X_data_w2v.append(tweet_embedding)\n",
    "    X_data_w2v = np.array(X_data_w2v)\n",
    "    return X_data_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1535a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings Train\n",
    "X_train_w2v = create_embeddings(train_tokens)\n",
    "# Embeddings Val\n",
    "X_val_w2v = create_embeddings(val_tokens)\n",
    "# Embeddings Test\n",
    "X_test_w2v = create_embeddings(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2a2191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"target\"].values\n",
    "y_val = df_val[\"target\"].values\n",
    "y_test = df_test[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d40b6e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07551973,  0.00938368, -0.06407581, ...,  0.18204895,\n",
       "        -0.15318605, -0.01367557],\n",
       "       [-0.01971032,  0.01715281, -0.04675406, ...,  0.18825826,\n",
       "        -0.13976344, -0.07234587],\n",
       "       [ 0.1500515 ,  0.05995679, -0.06817298, ...,  0.1617144 ,\n",
       "        -0.23004995, -0.06003911],\n",
       "       ...,\n",
       "       [ 0.12139874,  0.03876474, -0.17514214, ...,  0.44431865,\n",
       "        -0.26267782,  0.0842756 ],\n",
       "       [-0.10128947,  0.12634942, -0.06873481, ...,  0.25397936,\n",
       "        -0.14696279,  0.02413716],\n",
       "       [-0.1044376 ,  0.04425542, -0.15892135, ...,  0.17179362,\n",
       "        -0.03489589, -0.0925146 ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "442a2233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna\n",
    "def objective_word2vec(trial):\n",
    "    C = trial.suggest_float(\"C\", 1e-3, 1e2, log=True)\n",
    "    penalty = \"l2\"\n",
    "    solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\", \"lbfgs\"])\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        n_jobs=1,\n",
    "    )\n",
    "\n",
    "    # Validation crois√©e sur les embeddings Word2Vec\n",
    "    cv_score = cross_val_score(\n",
    "        model, X_train_w2v, y_train, cv=3, scoring=\"accuracy\", n_jobs=1\n",
    "    ).mean()  # Moyenne des 3 scores\n",
    "\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bb4c2c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 13:17:54,527] A new study created in RDB with name: Word2Vec_Optuna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec_Optuna OK\n"
     ]
    }
   ],
   "source": [
    "# Etude optuna\n",
    "study = optuna.create_study(\n",
    "    study_name=\"Word2Vec_Optuna\",\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///optuna_word2vec.db\",\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(  # Arr√™te les trials peu prometteurs\n",
    "        n_startup_trials=5  # Apr√®s 5 premiers trials\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"{study.study_name} OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4243b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:   4%|‚ñç         | 1/25 [00:02<00:51,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:34,561] Trial 50 finished with value: 0.7359374761897947 and parameters: {'C': 0.014558986305195467, 'solver': 'lbfgs'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:   8%|‚ñä         | 2/25 [00:03<00:38,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:35,900] Trial 51 finished with value: 0.742984391719946 and parameters: {'C': 0.21054831294749465, 'solver': 'saga'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  12%|‚ñà‚ñè        | 3/25 [00:04<00:34,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:37,340] Trial 52 finished with value: 0.743031260128275 and parameters: {'C': 0.1530477796709169, 'solver': 'saga'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  16%|‚ñà‚ñå        | 4/25 [00:06<00:36,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:39,334] Trial 53 finished with value: 0.7430781549033795 and parameters: {'C': 0.6752575700258877, 'solver': 'saga'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  20%|‚ñà‚ñà        | 5/25 [00:08<00:34,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:40,960] Trial 54 finished with value: 0.7429219090536289 and parameters: {'C': 0.7694052875760119, 'solver': 'saga'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:10<00:32,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:42,660] Trial 55 finished with value: 0.7430469095419636 and parameters: {'C': 1.3570237783721608, 'solver': 'saga'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:10<00:15,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:43,002] Trial 56 finished with value: 0.7428750216026287 and parameters: {'C': 0.4034715615563083, 'solver': 'lbfgs'}. Best is trial 27 with value: 0.7431875198938237.\n",
      "[I 2025-10-28 14:26:43,172] Trial 57 finished with value: 0.7174843206636831 and parameters: {'C': 0.0011887925044716822, 'solver': 'lbfgs'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:12<00:16,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:44,525] Trial 58 finished with value: 0.7428437857625485 and parameters: {'C': 3.09373563702467, 'solver': 'saga'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:12<00:13,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:45,149] Trial 59 finished with value: 0.7428906351282064 and parameters: {'C': 0.10295919396614156, 'solver': 'lbfgs'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:13<00:11,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:45,768] Trial 60 finished with value: 0.7430000286826574 and parameters: {'C': 0.6394772242546233, 'solver': 'lbfgs'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 0.743188:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:14<00:12,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:47,051] Trial 61 finished with value: 0.7430625216027203 and parameters: {'C': 0.2733228847030843, 'solver': 'saga'}. Best is trial 27 with value: 0.7431875198938237.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.743203:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:16<00:13,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:48,499] Trial 62 finished with value: 0.7432031458703786 and parameters: {'C': 0.30335167165464777, 'solver': 'saga'}. Best is trial 62 with value: 0.7432031458703786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 62. Best value: 0.743203:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:18<00:14,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:50,441] Trial 63 finished with value: 0.7429375342977735 and parameters: {'C': 1.0121712430577223, 'solver': 'saga'}. Best is trial 62 with value: 0.7432031458703786.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 64. Best value: 0.743344:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:19<00:13,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:51,727] Trial 64 finished with value: 0.7433437716028578 and parameters: {'C': 0.39132505525782074, 'solver': 'saga'}. Best is trial 64 with value: 0.7433437716028578.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:20<00:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:53,058] Trial 65 finished with value: 0.7433593968470021 and parameters: {'C': 0.3940199293182249, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:22<00:10,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:54,474] Trial 66 finished with value: 0.741828117793974 and parameters: {'C': 0.06731121089718446, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:23<00:09,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:55,804] Trial 67 finished with value: 0.7433593968470021 and parameters: {'C': 0.39501554637217173, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:24<00:07,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:57,068] Trial 68 finished with value: 0.7430781417199918 and parameters: {'C': 0.24572456423535094, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:25<00:06,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:58,400] Trial 69 finished with value: 0.7431718873255749 and parameters: {'C': 0.13621339423462991, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:27<00:05,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:26:59,599] Trial 70 finished with value: 0.7433281463587132 and parameters: {'C': 0.39867068095410413, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:28<00:03,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:27:00,882] Trial 71 finished with value: 0.7433281470911236 and parameters: {'C': 0.38983631709692246, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:29<00:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:27:02,245] Trial 72 finished with value: 0.7433281470911236 and parameters: {'C': 0.3886766224223183, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:30<00:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:27:03,398] Trial 73 finished with value: 0.7433593946497709 and parameters: {'C': 0.3463409343720759, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 65. Best value: 0.743359: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:32<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-28 14:27:04,576] Trial 74 finished with value: 0.7433125225793896 and parameters: {'C': 0.4035032030310661, 'solver': 'saga'}. Best is trial 65 with value: 0.7433593968470021.\n",
      "Meilleur score CV: 0.7434\n",
      "Meilleurs param√®tres: {'C': 0.3940199293182249, 'solver': 'saga'}\n",
      "Mod√®le final entra√Æn√© avec best_params\n",
      "Train Accuracy: 0.7452, Test Accuracy: 0.7358\n",
      "Train Precision: 0.7484, Test Precision: 0.7410\n",
      "Train Recall: 0.7397, Test Recall: 0.7267\n",
      "Train F1: 0.7440, Test F1: 0.7338\n",
      "Train ROC AUC: 0.8241, Test ROC AUC: 0.8141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/28 14:27:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "python(56407) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "\u001b[31m2025/10/28 14:27:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'w2v_100d_logreg'.\n",
      "Created version '1' of model 'w2v_100d_logreg'.\n"
     ]
    }
   ],
   "source": [
    "# D√©finir le nom de l'exp√©rience\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Word2Vec_optuna\"):\n",
    "\n",
    "    TRIAL_NUMBER = 25\n",
    "    EMBEDDING_DIM = X_train_w2v.shape[1]\n",
    "\n",
    "    # Optimisation\n",
    "    start_time = time.time()\n",
    "    study.optimize(\n",
    "        objective_word2vec, n_trials=TRIAL_NUMBER, n_jobs=1, show_progress_bar=True\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Log de configuration\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"n_trials\": TRIAL_NUMBER,\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"embeddings\": \"Word2Vec\",\n",
    "            \"model\": \"LogisticRegression\",\n",
    "            \"preprocessing\": \"text_preprocess_2\",\n",
    "            \"cv_folds\": 3,\n",
    "            \"train_samples\": len(X_train_w2v),\n",
    "            \"val_samples\": len(X_val_w2v),\n",
    "            \"test_samples\": len(X_test_w2v),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Meilleur score CV: {study.best_value:.4f}\")\n",
    "    print(f\"Meilleurs param√®tres: {study.best_params}\")\n",
    "\n",
    "    # Log r√©sultats Optuna\n",
    "    best_params = study.best_params\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            \"best_cv_accuracy\": study.best_value,\n",
    "            \"optimization_time_minutes\": elapsed_time / 60,\n",
    "            \"total_trials\": len(study.trials),\n",
    "        }\n",
    "    )\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"best_C\": best_params[\"C\"],\n",
    "            \"best_solver\": best_params[\"solver\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Mod√®le final avec best params\n",
    "    best_model = LogisticRegression(\n",
    "        C=best_params[\"C\"],\n",
    "        penalty=\"l2\",\n",
    "        solver=best_params[\"solver\"],\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model = best_model.fit(X_train_w2v, y_train)\n",
    "    print(\"Mod√®le final entra√Æn√© avec best_params\")\n",
    "\n",
    "    # Pr√©dictions\n",
    "    y_train_pred = model.predict(X_train_w2v)\n",
    "    y_train_pred_proba = model.predict_proba(X_train_w2v)[:, 1]\n",
    "    y_val_pred = model.predict(X_val_w2v)\n",
    "    y_val_pred_proba = model.predict_proba(X_val_w2v)[:, 1]\n",
    "    y_test_pred = model.predict(X_test_w2v)\n",
    "    y_test_pred_proba = model.predict_proba(X_test_w2v)[:, 1]\n",
    "\n",
    "    # M√©triques\n",
    "    train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = (\n",
    "        calcul_metriques(y_train, y_train_pred, y_train_pred_proba)\n",
    "    )\n",
    "    val_accuracy, val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "    test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = (\n",
    "        calcul_metriques(y_test, y_test_pred, y_test_pred_proba)\n",
    "    )\n",
    "\n",
    "    # Affichage console\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\n",
    "        f\"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\"\n",
    "    )\n",
    "    print(f\"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Train F1: {train_f1:.4f}, Test F1: {test_f1:.4f}\")\n",
    "    print(f\"Train ROC AUC: {train_roc_auc:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "    # Log m√©triques\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    # Overfitting checks\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    # Courbes ROC train/val/test\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - Train/Validation/Test (Word2Vec)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Sauvegarde & log de la figure\n",
    "    plt.savefig(\"roc_curve_w2v.png\")\n",
    "    mlflow.log_artifact(\"roc_curve_w2v.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Sauvegarde du mod√®le\n",
    "    mlflow.sklearn.log_model(\n",
    "        best_model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=f\"w2v_{EMBEDDING_DIM}d_logreg\",\n",
    "    )\n",
    "\n",
    "    # Tags\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"W2V_logreg\",\n",
    "            \"embedding_type\": \"Word2Vec_mean\",\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"dataset\": \"twitter_50K\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9159f57f",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e6781ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c6b02",
   "metadata": {},
   "source": [
    "## 25D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c8eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# Charger le fichier GloVe (format texte SANS header) en KeyedVectors \n",
    "path = \"/Users/skanderzahi/Desktop/glove.twitter.27B/glove.twitter.27B.25d.txt\"\n",
    "kv = KeyedVectors.load_word2vec_format(path, binary=False, no_header=True)\n",
    "print(kv.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8a4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex pr√©compil√©es pour gain d'execution\n",
    "# URL\n",
    "_re_URL = re.compile(r\"(https?://\\S+|www\\.\\S+)\")\n",
    "# Mention et hashtags\n",
    "_re_mention = re.compile(r\"\\@\\w+|\\#\")\n",
    "# Tokenisation\n",
    "_tweet_tokenizer = TweetTokenizer(\n",
    "    preserve_case=False, reduce_len=True, strip_handles=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc54c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetTokenize(text):\n",
    "    return _tweet_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb522b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_4(text):\n",
    "\n",
    "    text = _re_URL.sub(\"\", text)\n",
    "\n",
    "    text = re.sub(r\"\\@\\w+|\\#\", \"\", text)  # Mentions et hashtags\n",
    "\n",
    "    # Supprimer les chiffres seuls\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \"\", text)\n",
    "\n",
    "    # Tokenisation\n",
    "    tokens = tweetTokenize(text)\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15266735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lqsssdqsd coool ; ! :) qsdqsdqsq 6jhj'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Lqsssdqsd 4 coooool;!     #:)qsdqsdqsq https://www.tetx.com @ghgvh #6jhj\"\n",
    "preprocess_4(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acc686d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_3 train + val + test\n",
    "df_train[\"text_preprocess_glove\"] = df_train[\"text\"].apply(preprocess_4)\n",
    "df_val[\"text_preprocess_glove\"] = df_val[\"text\"].apply(preprocess_4)\n",
    "df_test[\"text_preprocess_glove\"] = df_test[\"text\"].apply(preprocess_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c57ca182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de texte avant/apr√®s text_preprocess_glove:\n",
      "Avant: I want the rain to go away! There has been too much of it lately \n",
      "Apr√®s: i want the rain to go away ! there has been too much of it lately\n"
     ]
    }
   ],
   "source": [
    "# V√©rification d'un √©chantillon\n",
    "print(\"Exemple de texte avant/apr√®s text_preprocess_glove:\")\n",
    "idx = 20000\n",
    "print(\"Avant:\", df_train[\"text\"].iloc[idx])\n",
    "print(\"Apr√®s:\", df_train[\"text_preprocess_glove\"].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "262b2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_doc(doc_tokens, model):\n",
    "\n",
    "    vectors = [model[word] for word in doc_tokens if word in model]\n",
    "\n",
    "    if vectors:  # au moins 1 mot connu\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # vecteur nul si aucun mot connu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b577bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"glove\"] = df_train[\"text_preprocess_glove\"].apply(\n",
    "    lambda doc: vectorize_doc(doc, kv)\n",
    ")\n",
    "df_val[\"glove\"] = df_val[\"text_preprocess_glove\"].apply(\n",
    "    lambda doc: vectorize_doc(doc, kv)\n",
    ")\n",
    "df_test[\"glove\"] = df_test[\"text_preprocess_glove\"].apply(\n",
    "    lambda doc: vectorize_doc(doc, kv)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b52282d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128000, 8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4a3b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en matrice nympy\n",
    "X_train_glove = np.stack(df_train[\"glove\"].values)\n",
    "X_val_glove = np.stack(df_val[\"glove\"].values)\n",
    "X_test_glove = np.stack(df_test[\"glove\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5939a917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21352138,  0.11457156,  0.01155368, ...,  0.02365484,\n",
       "         0.2680077 , -0.33272785],\n",
       "       [ 0.18230233,  0.04558141,  0.00125615, ..., -0.05999168,\n",
       "         0.26936516, -0.32877097],\n",
       "       [ 0.26467943,  0.05912201,  0.00954783, ..., -0.04138768,\n",
       "         0.1395708 , -0.32912165],\n",
       "       ...,\n",
       "       [ 0.24088505,  0.08252805,  0.01570519, ..., -0.04662155,\n",
       "         0.21732092, -0.34281415],\n",
       "       [ 0.30595204,  0.09139764,  0.0118228 , ..., -0.06901896,\n",
       "         0.24238832, -0.35126734],\n",
       "       [ 0.19691285,  0.02149937, -0.02555363, ...,  0.08218419,\n",
       "         0.19953941, -0.33092466]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "623f36f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64000, 25), (16000, 25), (20000, 25))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.shape, X_val_glove.shape, X_test_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d7b37828",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"target\"]\n",
    "y_val = df_val[\"target\"]\n",
    "y_test = df_test[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9467693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683563</td>\n",
       "      <td>0.099428</td>\n",
       "      <td>-0.229688</td>\n",
       "      <td>-0.185015</td>\n",
       "      <td>-0.062875</td>\n",
       "      <td>0.144975</td>\n",
       "      <td>-0.026317</td>\n",
       "      <td>1.920246</td>\n",
       "      <td>-0.073857</td>\n",
       "      <td>0.011684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.483427</td>\n",
       "      <td>-0.946862</td>\n",
       "      <td>-0.035915</td>\n",
       "      <td>-0.967893</td>\n",
       "      <td>0.326951</td>\n",
       "      <td>-0.170842</td>\n",
       "      <td>-0.380092</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>0.360821</td>\n",
       "      <td>0.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.678928</td>\n",
       "      <td>0.097845</td>\n",
       "      <td>-0.170613</td>\n",
       "      <td>-0.139523</td>\n",
       "      <td>-0.178400</td>\n",
       "      <td>0.158301</td>\n",
       "      <td>-0.154635</td>\n",
       "      <td>1.851948</td>\n",
       "      <td>-0.011850</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.353812</td>\n",
       "      <td>-0.854922</td>\n",
       "      <td>-0.024302</td>\n",
       "      <td>-0.952461</td>\n",
       "      <td>0.370596</td>\n",
       "      <td>-0.146648</td>\n",
       "      <td>-0.310857</td>\n",
       "      <td>0.358840</td>\n",
       "      <td>0.478374</td>\n",
       "      <td>0.259727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657574</td>\n",
       "      <td>0.220625</td>\n",
       "      <td>-0.164633</td>\n",
       "      <td>-0.186143</td>\n",
       "      <td>-0.113194</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>-0.020022</td>\n",
       "      <td>1.886971</td>\n",
       "      <td>-0.021003</td>\n",
       "      <td>0.024397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361414</td>\n",
       "      <td>-0.845798</td>\n",
       "      <td>-0.027195</td>\n",
       "      <td>-0.944911</td>\n",
       "      <td>0.324361</td>\n",
       "      <td>-0.182302</td>\n",
       "      <td>-0.356890</td>\n",
       "      <td>0.342174</td>\n",
       "      <td>0.368736</td>\n",
       "      <td>0.323047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725345</td>\n",
       "      <td>0.185879</td>\n",
       "      <td>-0.118584</td>\n",
       "      <td>-0.164877</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.109055</td>\n",
       "      <td>-0.007188</td>\n",
       "      <td>1.975496</td>\n",
       "      <td>-0.168578</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.551350</td>\n",
       "      <td>-1.020258</td>\n",
       "      <td>-0.100154</td>\n",
       "      <td>-0.887534</td>\n",
       "      <td>0.265497</td>\n",
       "      <td>-0.126399</td>\n",
       "      <td>-0.295413</td>\n",
       "      <td>0.409325</td>\n",
       "      <td>0.338336</td>\n",
       "      <td>0.421772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.594795</td>\n",
       "      <td>0.099822</td>\n",
       "      <td>-0.091307</td>\n",
       "      <td>-0.214199</td>\n",
       "      <td>-0.216401</td>\n",
       "      <td>0.152448</td>\n",
       "      <td>0.136176</td>\n",
       "      <td>1.684164</td>\n",
       "      <td>-0.102608</td>\n",
       "      <td>0.264450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395616</td>\n",
       "      <td>-0.665527</td>\n",
       "      <td>-0.116331</td>\n",
       "      <td>-0.984068</td>\n",
       "      <td>0.235169</td>\n",
       "      <td>-0.029264</td>\n",
       "      <td>-0.198324</td>\n",
       "      <td>0.260902</td>\n",
       "      <td>0.528516</td>\n",
       "      <td>0.299770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.624171</td>\n",
       "      <td>-0.075879</td>\n",
       "      <td>-0.166146</td>\n",
       "      <td>-0.244411</td>\n",
       "      <td>-0.075554</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>1.706552</td>\n",
       "      <td>-0.240711</td>\n",
       "      <td>0.264446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508429</td>\n",
       "      <td>-0.890471</td>\n",
       "      <td>-0.078428</td>\n",
       "      <td>-0.950007</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.109008</td>\n",
       "      <td>-0.269541</td>\n",
       "      <td>0.257833</td>\n",
       "      <td>0.387946</td>\n",
       "      <td>0.329562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.586201</td>\n",
       "      <td>0.206243</td>\n",
       "      <td>-0.283486</td>\n",
       "      <td>-0.212729</td>\n",
       "      <td>-0.146010</td>\n",
       "      <td>0.199475</td>\n",
       "      <td>-0.125786</td>\n",
       "      <td>1.886551</td>\n",
       "      <td>-0.105103</td>\n",
       "      <td>-0.134972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316563</td>\n",
       "      <td>-0.848680</td>\n",
       "      <td>-0.007551</td>\n",
       "      <td>-0.918648</td>\n",
       "      <td>0.466142</td>\n",
       "      <td>-0.167460</td>\n",
       "      <td>-0.462902</td>\n",
       "      <td>0.465393</td>\n",
       "      <td>0.299173</td>\n",
       "      <td>0.245711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.699001</td>\n",
       "      <td>0.237430</td>\n",
       "      <td>-0.221662</td>\n",
       "      <td>-0.247956</td>\n",
       "      <td>-0.053430</td>\n",
       "      <td>0.237346</td>\n",
       "      <td>0.040934</td>\n",
       "      <td>1.826516</td>\n",
       "      <td>0.088988</td>\n",
       "      <td>0.237795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612978</td>\n",
       "      <td>-0.681874</td>\n",
       "      <td>-0.175957</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>0.368767</td>\n",
       "      <td>-0.083790</td>\n",
       "      <td>-0.318216</td>\n",
       "      <td>0.439523</td>\n",
       "      <td>0.476513</td>\n",
       "      <td>0.276996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.767231</td>\n",
       "      <td>0.088743</td>\n",
       "      <td>-0.169909</td>\n",
       "      <td>-0.344879</td>\n",
       "      <td>0.136158</td>\n",
       "      <td>-0.025916</td>\n",
       "      <td>0.308373</td>\n",
       "      <td>2.222670</td>\n",
       "      <td>0.033677</td>\n",
       "      <td>0.325735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.709152</td>\n",
       "      <td>-1.089162</td>\n",
       "      <td>-0.085521</td>\n",
       "      <td>-0.808598</td>\n",
       "      <td>0.123300</td>\n",
       "      <td>-0.382298</td>\n",
       "      <td>-0.364624</td>\n",
       "      <td>0.381978</td>\n",
       "      <td>0.321825</td>\n",
       "      <td>0.428693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.662448</td>\n",
       "      <td>0.113429</td>\n",
       "      <td>-0.239159</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>-0.204316</td>\n",
       "      <td>0.138914</td>\n",
       "      <td>0.263405</td>\n",
       "      <td>1.665998</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.224594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474780</td>\n",
       "      <td>-0.698481</td>\n",
       "      <td>-0.134075</td>\n",
       "      <td>-1.101959</td>\n",
       "      <td>0.286647</td>\n",
       "      <td>-0.093548</td>\n",
       "      <td>-0.369766</td>\n",
       "      <td>0.419327</td>\n",
       "      <td>0.576775</td>\n",
       "      <td>0.254046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.683563  0.099428 -0.229688 -0.185015 -0.062875  0.144975 -0.026317   \n",
       "1  0.678928  0.097845 -0.170613 -0.139523 -0.178400  0.158301 -0.154635   \n",
       "2  0.657574  0.220625 -0.164633 -0.186143 -0.113194  0.131882 -0.020022   \n",
       "3  0.725345  0.185879 -0.118584 -0.164877  0.017729  0.109055 -0.007188   \n",
       "4  0.594795  0.099822 -0.091307 -0.214199 -0.216401  0.152448  0.136176   \n",
       "5  0.624171 -0.075879 -0.166146 -0.244411 -0.075554  0.141421  0.287842   \n",
       "6  0.586201  0.206243 -0.283486 -0.212729 -0.146010  0.199475 -0.125786   \n",
       "7  0.699001  0.237430 -0.221662 -0.247956 -0.053430  0.237346  0.040934   \n",
       "8  0.767231  0.088743 -0.169909 -0.344879  0.136158 -0.025916  0.308373   \n",
       "9  0.662448  0.113429 -0.239159 -0.304298 -0.204316  0.138914  0.263405   \n",
       "\n",
       "         7         8         9   ...        15        16        17        18  \\\n",
       "0  1.920246 -0.073857  0.011684  ... -0.483427 -0.946862 -0.035915 -0.967893   \n",
       "1  1.851948 -0.011850 -0.063522  ... -0.353812 -0.854922 -0.024302 -0.952461   \n",
       "2  1.886971 -0.021003  0.024397  ... -0.361414 -0.845798 -0.027195 -0.944911   \n",
       "3  1.975496 -0.168578 -0.008303  ... -0.551350 -1.020258 -0.100154 -0.887534   \n",
       "4  1.684164 -0.102608  0.264450  ... -0.395616 -0.665527 -0.116331 -0.984068   \n",
       "5  1.706552 -0.240711  0.264446  ... -0.508429 -0.890471 -0.078428 -0.950007   \n",
       "6  1.886551 -0.105103 -0.134972  ... -0.316563 -0.848680 -0.007551 -0.918648   \n",
       "7  1.826516  0.088988  0.237795  ... -0.612978 -0.681874 -0.175957 -0.952437   \n",
       "8  2.222670  0.033677  0.325735  ... -0.709152 -1.089162 -0.085521 -0.808598   \n",
       "9  1.665998 -0.003148  0.224594  ... -0.474780 -0.698481 -0.134075 -1.101959   \n",
       "\n",
       "         19        20        21        22        23        24  \n",
       "0  0.326951 -0.170842 -0.380092  0.409900  0.360821  0.349700  \n",
       "1  0.370596 -0.146648 -0.310857  0.358840  0.478374  0.259727  \n",
       "2  0.324361 -0.182302 -0.356890  0.342174  0.368736  0.323047  \n",
       "3  0.265497 -0.126399 -0.295413  0.409325  0.338336  0.421772  \n",
       "4  0.235169 -0.029264 -0.198324  0.260902  0.528516  0.299770  \n",
       "5 -0.000625 -0.109008 -0.269541  0.257833  0.387946  0.329562  \n",
       "6  0.466142 -0.167460 -0.462902  0.465393  0.299173  0.245711  \n",
       "7  0.368767 -0.083790 -0.318216  0.439523  0.476513  0.276996  \n",
       "8  0.123300 -0.382298 -0.364624  0.381978  0.321825  0.428693  \n",
       "9  0.286647 -0.093548 -0.369766  0.419327  0.576775  0.254046  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversion en DataFrame\n",
    "glove_df = pd.DataFrame(X_train_glove)\n",
    "print(glove_df.shape)\n",
    "glove_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dfd2d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l2, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   0.2s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..............C=0.001, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time=   1.4s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.1s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   0.2s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time=   0.5s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.3s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   2.9s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   3.2s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   3.4s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   2.9s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   1.2s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.5s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.6s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.7s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.6s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.6s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.8s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   4.4s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.8s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.9s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=   0.6s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   1.0s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   1.3s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=   1.1s\n",
      "[CV] END ................C=1.0, penalty=l2, solver=liblinear; total time=   0.9s\n",
      "[CV] END .....................C=1.0, penalty=l2, solver=saga; total time=   1.8s\n",
      "[CV] END .....................C=1.0, penalty=l2, solver=saga; total time=   1.7s\n",
      "[CV] END .....................C=1.0, penalty=l2, solver=saga; total time=   1.7s\n",
      "[CV] END .....................C=1.0, penalty=l2, solver=saga; total time=   1.9s\n",
      "[CV] END .....................C=1.0, penalty=l2, solver=saga; total time=   2.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  26.1s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  27.8s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  27.4s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  28.4s\n",
      "[CV] END .....................C=1.0, penalty=l1, solver=saga; total time=   2.3s\n",
      "[CV] END .....................C=1.0, penalty=l1, solver=saga; total time=   3.1s\n",
      "[CV] END .....................C=1.0, penalty=l1, solver=saga; total time=   3.3s\n",
      "[CV] END .....................C=1.0, penalty=l1, solver=saga; total time=   3.8s\n",
      "[CV] END ...............C=10.0, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END ...............C=10.0, penalty=l2, solver=liblinear; total time=   0.7s\n",
      "[CV] END .....................C=1.0, penalty=l1, solver=saga; total time=   3.3s\n",
      "[CV] END ...............C=10.0, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END ...............C=10.0, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END ...............C=10.0, penalty=l2, solver=liblinear; total time=   1.0s\n",
      "[CV] END ....................C=10.0, penalty=l2, solver=saga; total time=   4.2s\n",
      "[CV] END ....................C=10.0, penalty=l2, solver=saga; total time=   4.3s\n",
      "[CV] END ....................C=10.0, penalty=l2, solver=saga; total time=   4.4s\n",
      "[CV] END ....................C=10.0, penalty=l2, solver=saga; total time=   4.3s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  47.9s\n",
      "[CV] END ....................C=10.0, penalty=l2, solver=saga; total time=   4.1s\n",
      "[CV] END ................C=1.0, penalty=l1, solver=liblinear; total time= 2.1min\n",
      "[CV] END ................C=1.0, penalty=l1, solver=liblinear; total time= 2.4min\n",
      "[CV] END ................C=1.0, penalty=l1, solver=liblinear; total time= 2.2min\n",
      "[CV] END ....................C=10.0, penalty=l1, solver=saga; total time=   6.8s\n",
      "[CV] END ....................C=10.0, penalty=l1, solver=saga; total time=  11.1s\n",
      "[CV] END ....................C=10.0, penalty=l1, solver=saga; total time=   7.4s\n",
      "[CV] END ................C=1.0, penalty=l1, solver=liblinear; total time= 3.0min\n",
      "[CV] END ....................C=10.0, penalty=l1, solver=saga; total time=   8.1s\n",
      "[CV] END ....................C=10.0, penalty=l1, solver=saga; total time=   7.5s\n",
      "[CV] END ................C=1.0, penalty=l1, solver=liblinear; total time= 3.9min\n",
      "[CV] END ...............C=10.0, penalty=l1, solver=liblinear; total time= 5.7min\n",
      "[CV] END ...............C=10.0, penalty=l1, solver=liblinear; total time= 5.9min\n",
      "[CV] END ...............C=10.0, penalty=l1, solver=liblinear; total time= 6.0min\n",
      "[CV] END ...............C=10.0, penalty=l1, solver=liblinear; total time= 4.5min\n",
      "[CV] END ...............C=10.0, penalty=l1, solver=liblinear; total time= 4.6min\n",
      "Best Hyperparameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Train Accuracy: 0.5708, Test Accuracy: 0.5704\n",
      "Train Precision: 0.5762, Test Precision: 0.5778\n",
      "Train Recall: 0.5402, Test Recall: 0.5301\n",
      "Train F1 Score: 0.5576, Test F1 Score: 0.5529\n",
      "Train ROC AUC: 0.6000, Test ROC AUC: 0.5944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/16 18:05:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/16 18:05:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'LogisticRegression_Tweets_Sentiment' already exists. Creating a new version of this model...\n",
      "Created version '11' of model 'LogisticRegression_Tweets_Sentiment'.\n",
      "2025/10/16 18:05:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report Test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.59      9977\n",
      "           1       0.58      0.53      0.55     10023\n",
      "\n",
      "    accuracy                           0.57     20000\n",
      "   macro avg       0.57      0.57      0.57     20000\n",
      "weighted avg       0.57      0.57      0.57     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/16 18:05:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1.0, 10.0],  # [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\", \"l1\"],\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "}\n",
    "\n",
    "best_model, grid = process_params_mlflow(\n",
    "    run_name=\"glove_25D_GridSearch_LogReg\",\n",
    "    X_train=X_train_glove,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_glove,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test_glove,\n",
    "    y_test=y_test,\n",
    "    param_grid=param_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ec86b",
   "metadata": {},
   "source": [
    "## 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea7143e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier GloVe (format texte SANS header) en KeyedVectors\n",
    "path = \"/Users/skanderzahi/Desktop/glove.twitter.27B/glove.twitter.27B.100d.txt\"\n",
    "kv = KeyedVectors.load_word2vec_format(path, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbfab533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"glove\"] = df_train[\"text_preprocess_glove\"].apply(\n",
    "    lambda doc: vectorize_doc(doc, kv)\n",
    ")\n",
    "df_val[\"glove\"] = df_val[\"text_preprocess_glove\"].apply(\n",
    "    lambda doc: vectorize_doc(doc, kv)\n",
    ")\n",
    "df_test[\"glove\"] = df_test[\"text_preprocess_glove\"].apply(\n",
    "    lambda doc: vectorize_doc(doc, kv)\n",
    ")\n",
    "# Conversion en matrice nympy\n",
    "X_train_glove = np.stack(df_train[\"glove\"].values)\n",
    "X_val_glove = np.stack(df_val[\"glove\"].values)\n",
    "X_test_glove = np.stack(df_test[\"glove\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00648a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "04222585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END ....................C=5.0, penalty=l2, solver=lbfgs; total time=   1.7s\n",
      "[CV] END ....................C=5.0, penalty=l2, solver=lbfgs; total time=   1.8s\n",
      "[CV] END ....................C=5.0, penalty=l2, solver=lbfgs; total time=   2.0s\n",
      "[CV] END ....................C=5.0, penalty=l2, solver=lbfgs; total time=   2.3s\n",
      "[CV] END ....................C=5.0, penalty=l2, solver=lbfgs; total time=   3.1s\n",
      "Best Hyperparameters: {'C': 5.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/17 11:21:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5975, Test Accuracy: 0.5919\n",
      "Train Precision: 0.6047, Test Precision: 0.6011\n",
      "Train Recall: 0.5665, Test Recall: 0.5521\n",
      "Train F1 Score: 0.5850, Test F1 Score: 0.5756\n",
      "Train ROC AUC: 0.6343, Test ROC AUC: 0.6274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/17 11:21:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'LogisticRegression_Tweets_Sentiment' already exists. Creating a new version of this model...\n",
      "Created version '14' of model 'LogisticRegression_Tweets_Sentiment'.\n",
      "2025/10/17 11:21:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report Test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.61      9977\n",
      "           1       0.60      0.55      0.58     10023\n",
      "\n",
      "    accuracy                           0.59     20000\n",
      "   macro avg       0.59      0.59      0.59     20000\n",
      "weighted avg       0.59      0.59      0.59     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/17 11:21:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": [5.0],  # [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\n",
    "        \"lbfgs\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "best_model, grid = process_params_mlflow(\n",
    "    run_name=\"glove_100D_GridSearch_LogReg\",\n",
    "    X_train=X_train_glove,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_glove,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test_glove,\n",
    "    y_test=y_test,\n",
    "    param_grid=param_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b547371",
   "metadata": {},
   "source": [
    "## Optuna + MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3504646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_embedding(df_train, df_val, df_test):\n",
    "\n",
    "    # Charger le fichier GloVe (format texte SANS header) en KeyedVectors\n",
    "    path = \"/Users/skanderzahi/Desktop/glove.twitter.27B/glove.twitter.27B.100d.txt\"\n",
    "    kv = KeyedVectors.load_word2vec_format(path, binary=False, no_header=True)\n",
    "\n",
    "    # Regex pr√©compil√©es pour gain d'execution\n",
    "\n",
    "    # URL\n",
    "    _re_URL = re.compile(r\"(https?://\\S+|www\\.\\S+)\")\n",
    "\n",
    "    # Mention et hashtags\n",
    "    _re_mention_hashtag = re.compile(r\"\\@\\w+|\\#\")\n",
    "\n",
    "    # Supprimer les chiffres seuls\n",
    "    _re_digits = re.compile(r\"\\b\\d+\\b\")\n",
    "\n",
    "    # Tokenisation\n",
    "    _tweet_tokenizer = TweetTokenizer(\n",
    "        preserve_case=False, reduce_len=True, strip_handles=False\n",
    "    )\n",
    "\n",
    "    def tweetTokenize(text):\n",
    "        return _tweet_tokenizer.tokenize(text)\n",
    "\n",
    "    def preprocess_4(text):\n",
    "        text = _re_URL.sub(\"\", text)\n",
    "        text = _re_mention_hashtag.sub(\"\", text)\n",
    "        text = _re_digits.sub(\"\", text)\n",
    "        # Tokenisation\n",
    "        tokens = tweetTokenize(text)\n",
    "        text = \" \".join(tokens)\n",
    "        return text\n",
    "\n",
    "    df_train[\"text_preprocess_glove\"] = df_train[\"text\"].apply(preprocess_4)\n",
    "    df_val[\"text_preprocess_glove\"] = df_val[\"text\"].apply(preprocess_4)\n",
    "    df_test[\"text_preprocess_glove\"] = df_test[\"text\"].apply(preprocess_4)\n",
    "\n",
    "    def vectorize_doc(doc_tokens, model):\n",
    "        vectors = [model[word] for word in doc_tokens if word in model]\n",
    "        if vectors:  # au moins 1 mot connu\n",
    "            return np.mean(vectors, axis=0)\n",
    "        else:\n",
    "            return np.zeros(model.vector_size)  # vecteur nul si aucun mot connu\n",
    "\n",
    "    df_train[\"glove\"] = df_train[\"text_preprocess_glove\"].apply(\n",
    "        lambda doc: vectorize_doc(doc, kv)\n",
    "    )\n",
    "    df_val[\"glove\"] = df_val[\"text_preprocess_glove\"].apply(\n",
    "        lambda doc: vectorize_doc(doc, kv)\n",
    "    )\n",
    "    df_test[\"glove\"] = df_test[\"text_preprocess_glove\"].apply(\n",
    "        lambda doc: vectorize_doc(doc, kv)\n",
    "    )\n",
    "\n",
    "    X_train_glove = np.stack(df_train[\"glove\"].values)\n",
    "    X_val_glove = np.stack(df_val[\"glove\"].values)\n",
    "    X_test_glove = np.stack(df_test[\"glove\"].values)\n",
    "\n",
    "    y_train = df_train[\"target\"]\n",
    "    y_val = df_val[\"target\"]\n",
    "    y_test = df_test[\"target\"]\n",
    "\n",
    "    return X_train_glove, X_val_glove, X_test_glove, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fb4c477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64000, 6), (16000, 6), (20000, 6))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47b3989f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 6), (8000, 6), (10000, 6))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sample(frac=0.5, random_state=42)\n",
    "df_test = df_test.sample(frac=0.5, random_state=42)\n",
    "df_val = df_val.sample(frac=0.5, random_state=42)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d559fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove, X_val_glove, X_test_glove, y_train, y_val, y_test = glove_embedding(\n",
    "    df_train, df_val, df_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "860baf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ac0bd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©finir le nom de l'exp√©rience\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ead3e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_glove(trial):\n",
    "    C = trial.suggest_float(\"C\", 1e-3, 1e2, log=True)\n",
    "    penalty = \"l2\"\n",
    "    solver = \"liblinear\"\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        random_state=42,\n",
    "        n_jobs=1,\n",
    "    )\n",
    "    # Validation crois√©e sur les embeddings GloVe\n",
    "    cv_score = cross_val_score(\n",
    "        model, X_train_glove, y_train, cv=3, scoring=\"accuracy\", n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "725bc9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 19:26:14,249] Using an existing study with name 'GloVe_Optuna' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe_Optuna OK\n"
     ]
    }
   ],
   "source": [
    "# Etude optuna\n",
    "study = optuna.create_study(\n",
    "    study_name=\"GloVe_Optuna\",\n",
    "    direction=\"maximize\",  # Maxsimizer accuracy\n",
    "    storage=\"sqlite:///optuna_glove.db\",\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5\n",
    "    ),  # => Arr√™te les trials peu prometteurs\n",
    ")\n",
    "print(f\"{study.study_name} OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:   4%|‚ñç         | 1/25 [00:04<01:58,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:24,238] Trial 133 finished with value: 0.5988749132763425 and parameters: {'C': 80.99505524998528}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:   8%|‚ñä         | 2/25 [00:08<01:29,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:27,368] Trial 134 finished with value: 0.5989061417913569 and parameters: {'C': 38.917377782689684}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  12%|‚ñà‚ñè        | 3/25 [00:11<01:20,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:30,739] Trial 135 finished with value: 0.5990311583936826 and parameters: {'C': 65.19342147200858}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  16%|‚ñà‚ñå        | 4/25 [00:15<01:17,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:34,530] Trial 136 finished with value: 0.5991249171832029 and parameters: {'C': 97.8000659484504}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  20%|‚ñà‚ñà        | 5/25 [00:19<01:17,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:38,708] Trial 137 finished with value: 0.5991249142534237 and parameters: {'C': 97.14399701885931}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  24%|‚ñà‚ñà‚ñç       | 6/25 [00:22<01:09,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:41,960] Trial 138 finished with value: 0.5989373996041623 and parameters: {'C': 49.38082454181492}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  28%|‚ñà‚ñà‚ñä       | 7/25 [00:25<01:03,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:45,272] Trial 139 finished with value: 0.5988436583933163 and parameters: {'C': 69.7381219425058}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:29<01:01,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:48,986] Trial 140 finished with value: 0.5991874152301389 and parameters: {'C': 98.51560585333273}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:33<00:57,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:52,657] Trial 141 finished with value: 0.5988436583933163 and parameters: {'C': 78.67861889831522}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [00:36<00:53,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:44:56,191] Trial 142 finished with value: 0.5990311583936826 and parameters: {'C': 59.070565750812165}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:41<00:53,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:00,416] Trial 143 finished with value: 0.59915616913645 and parameters: {'C': 99.88510023556462}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:44<00:46,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:03,511] Trial 144 finished with value: 0.5989373966743833 and parameters: {'C': 46.22607777814541}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:47<00:42,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:07,060] Trial 145 finished with value: 0.5988124064400693 and parameters: {'C': 74.64422642333375}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:50<00:36,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:09,725] Trial 146 finished with value: 0.598874895697668 and parameters: {'C': 39.638314594134215}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:54<00:35,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:13,936] Trial 147 finished with value: 0.5989374171828366 and parameters: {'C': 83.98638372836598}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:58<00:33,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:18,031] Trial 148 finished with value: 0.5991249142534237 and parameters: {'C': 99.80235353839578}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [01:02<00:28,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:21,383] Trial 149 finished with value: 0.5990311554639035 and parameters: {'C': 60.15184682285308}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [01:05<00:24,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:24,683] Trial 150 finished with value: 0.5989061564402524 and parameters: {'C': 67.5561413911823}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [01:08<00:21,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:28,140] Trial 151 finished with value: 0.5989374113232785 and parameters: {'C': 52.318882233613365}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [01:13<00:18,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:32,300] Trial 152 finished with value: 0.599218670113165 and parameters: {'C': 99.25301167351618}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [01:17<00:15,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:36,782] Trial 153 finished with value: 0.59915616913645 and parameters: {'C': 99.94479510664065}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [01:21<00:11,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:40,505] Trial 154 finished with value: 0.5989061593700314 and parameters: {'C': 71.11693554106998}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [01:22<00:06,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:41,802] Trial 155 finished with value: 0.5964686300674799 and parameters: {'C': 1.8949211846300202}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [01:26<00:03,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:45,622] Trial 156 finished with value: 0.5988749103465634 and parameters: {'C': 79.3342085248064}. Best is trial 42 with value: 0.599281168160101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 42. Best value: 0.599281: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [01:30<00:00,  3.61s/it]\n",
      "/opt/anaconda3/envs/glove_test/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1305: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:45:49,615] Trial 157 finished with value: 0.5991561662066709 and parameters: {'C': 96.86727474485859}. Best is trial 42 with value: 0.599281168160101.\n",
      "Meilleur score CV: 0.5993\n",
      " Meilleurs param√®tres: {'C': 98.29105404540472}\n",
      "Mod√®le final entra√Æn√© avec best_params\n",
      "Train Accuracy: 0.6009, Test Accuracy: 0.5914\n",
      "Train Precision: 0.6089, Test Precision: 0.5972\n",
      "Train Recall: 0.5677, Test Recall: 0.5501\n",
      "Train F1 Score: 0.5876, Test F1 Score: 0.5727\n",
      "Train ROC AUC: 0.6384, Test ROC AUC: 0.6277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/22 21:45:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/22 21:45:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'glove_100d_logreg'.\n",
      "Created version '1' of model 'glove_100d_logreg'.\n"
     ]
    }
   ],
   "source": [
    "# mlflow\n",
    "with mlflow.start_run(run_name=\"GloVe_optuna\"):\n",
    "\n",
    "    TRIAL_NUMBER = 25\n",
    "    EMBEDDING_DIM = X_train_glove.shape[1]\n",
    "\n",
    "    # Optimisation\n",
    "    start_time = time.time()\n",
    "\n",
    "    study.optimize(\n",
    "        objective_glove, n_trials=TRIAL_NUMBER, n_jobs=1, show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Log de configuration\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"n_trials\": TRIAL_NUMBER,\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"embeddings\": \"GloVe\",\n",
    "            \"model\": \"LogisticRegression\",\n",
    "            \"preprocessing\": \"preprocess_4\",\n",
    "            \"cv_folds\": 3,\n",
    "            \"train_samples\": len(X_train_glove),\n",
    "            \"val_samples\": len(X_val_glove),\n",
    "            \"test_samples\": len(X_test_glove),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Meilleur score CV: {study.best_value:.4f}\")\n",
    "    print(f\" Meilleurs param√®tres: {study.best_params}\")\n",
    "\n",
    "    # Log des r√©sultats optimisation\n",
    "    best_params = study.best_params\n",
    "\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            \"best_cv_accuracy\": study.best_value,\n",
    "            \"optimization_time_minutes\": elapsed_time / 60,\n",
    "            \"total_trials\": len(study.trials),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"best_C\": best_params[\"C\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # solver = \"liblinear\" if best_params[\"penalty\"] == \"l1\" else \"lbfgs\"\n",
    "    # Construction et entra√Ænement du meilleur mod√®le\n",
    "    best_model = LogisticRegression(\n",
    "        C=best_params[\"C\"],\n",
    "        penalty=\"l2\",\n",
    "        solver=\"liblinear\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model = best_model.fit(X_train_glove, y_train)\n",
    "    print(\"Mod√®le final entra√Æn√© avec best_params\")\n",
    "\n",
    "    # Pr√©dictions\n",
    "    y_train_pred = model.predict(X_train_glove)\n",
    "    y_train_pred_proba = model.predict_proba(X_train_glove)[:, 1]\n",
    "    y_val_pred = model.predict(X_val_glove)\n",
    "    y_val_pred_proba = model.predict_proba(X_val_glove)[:, 1]\n",
    "    y_test_pred = model.predict(X_test_glove)\n",
    "    y_test_pred_proba = model.predict_proba(X_test_glove)[:, 1]\n",
    "\n",
    "    # Calcul des m√©triques\n",
    "    train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = (\n",
    "        calcul_metriques(y_train, y_train_pred, y_train_pred_proba)\n",
    "    )\n",
    "    val_accuracy, val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "    test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = (\n",
    "        calcul_metriques(y_test, y_test_pred, y_test_pred_proba)\n",
    "    )\n",
    "\n",
    "    # Affichage des m√©triques train et test\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\n",
    "        f\"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\"\n",
    "    )\n",
    "    print(f\"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"Train ROC AUC: {train_roc_auc:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "    # M√©triques train\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # M√©triques val\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    # M√©triques test\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    # Overfitting check\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    # Courbe ROC pour train, val,test\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - Train/Validation/Test\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Sauvegarder l'image\n",
    "    plt.savefig(\"roc_curve_glove.png\")\n",
    "    mlflow.log_artifact(\"roc_curve_glove.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Sauvegarde du mod√®le\n",
    "    mlflow.sklearn.log_model(\n",
    "        best_model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=f\"glove_{EMBEDDING_DIM}d_logreg\",\n",
    "    )\n",
    "    # Taggs\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"GloVe_logreg\",\n",
    "            \"embedding_type\": \"GloVe\",\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"dataset\": \"twitter_50K\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922b9c9",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c9897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88f0cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 20:44:02.594588: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-11-20 20:44:02.594627: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-11-20 20:44:02.594642: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-11-20 20:44:02.594917: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-20 20:44:02.594938: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-11-20 20:44:05.756480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Chargement du mod√®le\n",
    "model_use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8366f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_5_use(text):\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = _re_URL.sub(\"\", text)\n",
    "\n",
    "    text = re.sub(r\"\\@\\w+|\\#\", \"\", text)  # Mentions et hashtags\n",
    "\n",
    "    # Supprimer les chiffres seuls\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \"\", text)\n",
    "\n",
    "    # Supprimer espaces multiples\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    # pas d'utilit√© de tokenisation pour use (attend txt brut)\n",
    "    # Tokenisation\n",
    "    # tokens = tweetTokenize(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99129133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_4 train + val + test\n",
    "df_train[\"text_preprocess_use\"] = df_train[\"text\"].apply(preprocess_5_use)\n",
    "df_val[\"text_preprocess_use\"] = df_val[\"text\"].apply(preprocess_5_use)\n",
    "df_test[\"text_preprocess_use\"] = df_test[\"text\"].apply(preprocess_5_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d429b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_use_with_batch(text, model, batch_size=1000):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(text), batch_size):\n",
    "        batch = text[i : i + batch_size]\n",
    "        batch_embeddings = model(batch)\n",
    "        all_embeddings.append(batch_embeddings.numpy())\n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19753e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = df_train[\"text_preprocess_use\"].tolist()\n",
    "list_val = df_val[\"text_preprocess_use\"].tolist()\n",
    "list_test = df_test[\"text_preprocess_use\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3cf2b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_use = vectorize_use_with_batch(list_train, model_use)\n",
    "X_val_use = vectorize_use_with_batch(list_val, model_use)\n",
    "X_test_use = vectorize_use_with_batch(list_test, model_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61291378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0530affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p7_use_m2/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................C=2.0, penalty=l2, solver=liblinear; total time=   3.7s\n",
      "[CV] END ................C=2.0, penalty=l2, solver=liblinear; total time=   3.8s\n",
      "[CV] END ................C=2.0, penalty=l2, solver=liblinear; total time=   3.9s\n",
      "[CV] END ................C=2.0, penalty=l2, solver=liblinear; total time=   4.3s\n",
      "[CV] END ................C=2.0, penalty=l2, solver=liblinear; total time=   2.5s\n",
      "Best Hyperparameters: {'C': 2.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Train Accuracy: 0.7878, Test Accuracy: 0.7803\n",
      "Train Precision: 0.7891, Test Precision: 0.7771\n",
      "Train Recall: 0.7865, Test Recall: 0.7832\n",
      "Train F1 Score: 0.7878, Test F1 Score: 0.7801\n",
      "Train ROC AUC: 0.8692, Test ROC AUC: 0.8581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/20 20:50:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "When an mlflow-artifacts URI was supplied, the tracking URI must be a valid http or https URI, but it was currently set to file:///Users/skanderzahi/Desktop/P7/projet_7/mlruns. Perhaps you forgot to set the tracking URI to the running MLflow server. To set the tracking URI, use either of the following methods:\n1. Set the MLFLOW_TRACKING_URI environment variable to the desired tracking URI. `export MLFLOW_TRACKING_URI=http://localhost:5000`\n2. Set the tracking URI programmatically by calling `mlflow.set_tracking_uri`. `mlflow.set_tracking_uri('http://localhost:5000')`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m param_grid = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m         \u001b[32m2.0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     ],\n\u001b[32m     13\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m best_model, grid = \u001b[43mprocess_params_mlflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUSE_GridSearch_LogReg_final\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mprocess_params_mlflow\u001b[39m\u001b[34m(run_name, X_train, X_test, X_val, y_train, y_test, y_val, param_grid)\u001b[39m\n\u001b[32m     96\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mval_test_f1_gap\u001b[39m\u001b[33m\"\u001b[39m, val_f1 - test_f1)\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Mod√®le\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLogisticRegression_Tweets_Sentiment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# Courbe ROC\u001b[39;00m\n\u001b[32m    106\u001b[39m fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/sklearn/__init__.py:426\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata, params, tags, model_type, step, model_id, name)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS.format(package_name=\u001b[33m\"\u001b[39m\u001b[33mscikit-learn\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_model\u001b[39m(\n\u001b[32m    336\u001b[39m     sk_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    356\u001b[39m ):\n\u001b[32m    357\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[33;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[33;03m    containing the following flavors:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    424\u001b[39m \n\u001b[32m    425\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/models/model.py:1297\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[39m\n\u001b[32m   1294\u001b[39m     \u001b[38;5;66;03m# mlflow_model is updated, rewrite the MLmodel file\u001b[39;00m\n\u001b[32m   1295\u001b[39m     mlflow_model.save(os.path.join(local_path, MLMODEL_FILE_NAME))\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[38;5;66;03m# If the model was previously identified as external, delete the tag because\u001b[39;00m\n\u001b[32m   1299\u001b[39m \u001b[38;5;66;03m# the model now has artifacts in MLflow Model format\u001b[39;00m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model.tags.get(MLFLOW_MODEL_IS_EXTERNAL, \u001b[33m\"\u001b[39m\u001b[33mfalse\u001b[39m\u001b[33m\"\u001b[39m).lower() == \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/tracking/client.py:5643\u001b[39m, in \u001b[36mMlflowClient.log_model_artifacts\u001b[39m\u001b[34m(self, model_id, local_dir)\u001b[39m\n\u001b[32m   5632\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_model_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_id: \u001b[38;5;28mstr\u001b[39m, local_dir: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5633\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5634\u001b[39m \u001b[33;03m    Upload a set of artifacts to the specified logged model.\u001b[39;00m\n\u001b[32m   5635\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5641\u001b[39m \u001b[33;03m        None\u001b[39;00m\n\u001b[32m   5642\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:911\u001b[39m, in \u001b[36mTrackingServiceClient.log_model_artifacts\u001b[39m\u001b[34m(self, model_id, local_dir)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_model_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_id: \u001b[38;5;28mstr\u001b[39m, local_dir: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m911\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogged_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.log_artifacts(local_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:650\u001b[39m, in \u001b[36mTrackingServiceClient._get_artifact_repo\u001b[39m\u001b[34m(self, resource_id, resource)\u001b[39m\n\u001b[32m    645\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected resource type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    647\u001b[39m artifact_uri = add_databricks_profile_info_to_artifact_uri(\n\u001b[32m    648\u001b[39m     artifact_location, \u001b[38;5;28mself\u001b[39m.tracking_uri\n\u001b[32m    649\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m artifact_repo = \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;66;03m# Cache the artifact repo to avoid a future network call, removing the oldest\u001b[39;00m\n\u001b[32m    652\u001b[39m \u001b[38;5;66;03m# entry in the cache if there are too many elements\u001b[39;00m\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(utils._artifact_repos_cache) > \u001b[32m1024\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:147\u001b[39m, in \u001b[36mget_artifact_repository\u001b[39m\u001b[34m(artifact_uri, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_artifact_repository\u001b[39m(\n\u001b[32m    129\u001b[39m     artifact_uri: \u001b[38;5;28mstr\u001b[39m, tracking_uri: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, registry_uri: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    130\u001b[39m ) -> ArtifactRepository:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m \u001b[33;03m        requirements.\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_artifact_repository_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry_uri\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/store/artifact/artifact_repository_registry.py:83\u001b[39m, in \u001b[36mArtifactRepositoryRegistry.get_artifact_repository\u001b[39m\u001b[34m(self, artifact_uri, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m     80\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     81\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._registry.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistry_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/store/artifact/mlflow_artifacts_repo.py:55\u001b[39m, in \u001b[36mMlflowArtifactsRepository.__init__\u001b[39m\u001b[34m(self, artifact_uri, tracking_uri, registry_uri)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mself\u001b[39m, artifact_uri: \u001b[38;5;28mstr\u001b[39m, tracking_uri: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, registry_uri: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     52\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     53\u001b[39m     effective_tracking_uri = tracking_uri \u001b[38;5;129;01mor\u001b[39;00m get_tracking_uri()\n\u001b[32m     54\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresolve_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_tracking_uri\u001b[49m\u001b[43m)\u001b[49m, tracking_uri, registry_uri\n\u001b[32m     56\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/store/artifact/mlflow_artifacts_repo.py:70\u001b[39m, in \u001b[36mMlflowArtifactsRepository.resolve_uri\u001b[39m\u001b[34m(cls, artifact_uri, tracking_uri)\u001b[39m\n\u001b[32m     67\u001b[39m _validate_port_mapped_to_hostname(uri_parse)\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Check that tracking uri is http or https\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43m_validate_uri_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack_parse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m uri_parse.path == \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# root directory; build simple path\u001b[39;00m\n\u001b[32m     73\u001b[39m     resolved = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00muri_parse.path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/p7_use_m2/lib/python3.11/site-packages/mlflow/store/artifact/mlflow_artifacts_repo.py:35\u001b[39m, in \u001b[36m_validate_uri_scheme\u001b[39m\u001b[34m(parsed_uri)\u001b[39m\n\u001b[32m     33\u001b[39m allowable_schemes = {\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parsed_uri.scheme \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowable_schemes:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhen an mlflow-artifacts URI was supplied, the tracking URI must be a valid \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttp or https URI, but it was currently set to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_uri.geturl()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPerhaps you forgot to set the tracking URI to the running MLflow server. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo set the tracking URI, use either of the following methods:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m1. Set the MLFLOW_TRACKING_URI environment variable to the desired tracking URI. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`export MLFLOW_TRACKING_URI=http://localhost:5000`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m2. Set the tracking URI programmatically by calling `mlflow.set_tracking_uri`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`mlflow.set_tracking_uri(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttp://localhost:5000\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     44\u001b[39m     )\n",
      "\u001b[31mMlflowException\u001b[39m: When an mlflow-artifacts URI was supplied, the tracking URI must be a valid http or https URI, but it was currently set to file:///Users/skanderzahi/Desktop/P7/projet_7/mlruns. Perhaps you forgot to set the tracking URI to the running MLflow server. To set the tracking URI, use either of the following methods:\n1. Set the MLFLOW_TRACKING_URI environment variable to the desired tracking URI. `export MLFLOW_TRACKING_URI=http://localhost:5000`\n2. Set the tracking URI programmatically by calling `mlflow.set_tracking_uri`. `mlflow.set_tracking_uri('http://localhost:5000')`"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": [\n",
    "        2.0,\n",
    "        # 5.0,\n",
    "        # 10.0,\n",
    "    ],  # [0.001, 0.01, 0.1, 1.0, 10.0],  # [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\n",
    "        \"liblinear\"\n",
    "        # ,\"saga\",\n",
    "        # \"lbfgs\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "best_model, grid = process_params_mlflow(\n",
    "    run_name=\"USE_GridSearch_LogReg_final\",\n",
    "    X_train=X_train_use,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_use,\n",
    "    y_val=y_val,\n",
    "    X_test=X_test_use,\n",
    "    y_test=y_test,\n",
    "    param_grid=param_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831716a5",
   "metadata": {},
   "source": [
    "## Optuna + MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le nom de l'exp√©rience\n",
    "experiment_name = \"p7_air_paradis\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "577a30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_use(trial):\n",
    "    C = trial.suggest_float(\"C\", 1e-3, 1e2, log=True)\n",
    "    penalty = \"l2\"\n",
    "    solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\", \"lbfgs\"])\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        random_state=42,\n",
    "        n_jobs=1,\n",
    "    )\n",
    "    # Validation crois√©e sur les embeddings GloVe\n",
    "    cv_score = cross_val_score(\n",
    "        model, X_train_glove, y_train, cv=3, scoring=\"accuracy\", n_jobs=1\n",
    "    ).mean()\n",
    "\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "090193d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 21:57:26,830] A new study created in RDB with name: USE_Optuna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_Optuna OK\n"
     ]
    }
   ],
   "source": [
    "# Etude optuna\n",
    "study = optuna.create_study(\n",
    "    study_name=\"USE_Optuna\",\n",
    "    direction=\"maximize\",  # Maxsimizer accuracy\n",
    "    storage=\"sqlite:///optuna_use.db\",\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=5\n",
    "    ),  # => Arr√™te les trials peu prometteurs\n",
    ")\n",
    "print(f\"{study.study_name} OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e86470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run USE_optuna at: http://127.0.0.1:5000/#/experiments/379503310426968982/runs/3784d41def764788a39dd6569ffa1de3\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/379503310426968982\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_name=\u001b[33m\"\u001b[39m\u001b[33mUSE_optuna\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      4\u001b[39m     TRIAL_NUMBER = \u001b[32m25\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     EMBEDDING_DIM = \u001b[43mX_train_use\u001b[49m.shape[\u001b[32m1\u001b[39m]\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Optimisation\u001b[39;00m\n\u001b[32m      8\u001b[39m     start_time = time.time()\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_use' is not defined"
     ]
    }
   ],
   "source": [
    "# Etude optuna\n",
    "with mlflow.start_run(run_name=\"USE_optuna\"):\n",
    "\n",
    "    TRIAL_NUMBER = 25\n",
    "    EMBEDDING_DIM = X_train_use.shape[1]\n",
    "\n",
    "    # Optimisation\n",
    "    start_time = time.time()\n",
    "\n",
    "    study.optimize(\n",
    "        objective_use, n_trials=TRIAL_NUMBER, n_jobs=1, show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Log de configuration\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"n_trials\": TRIAL_NUMBER,\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"embeddings\": \"USE\",\n",
    "            \"model\": \"LogisticRegression\",\n",
    "            \"preprocessing\": \"preprocess_use\",\n",
    "            \"cv_folds\": 3,\n",
    "            \"train_samples\": len(X_train_use),\n",
    "            \"val_samples\": len(X_val_use),\n",
    "            \"test_samples\": len(X_test_use),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Meilleur score CV: {study.best_value:.4f}\")\n",
    "    print(f\" Meilleurs param√®tres: {study.best_params}\")\n",
    "\n",
    "    # Log des r√©sultats optimisation\n",
    "    best_params = study.best_params\n",
    "\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            \"best_cv_accuracy\": study.best_value,\n",
    "            \"optimization_time_minutes\": elapsed_time / 60,\n",
    "            \"total_trials\": len(study.trials),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"best_C\": best_params[\"C\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # solver = \"liblinear\" if best_params[\"penalty\"] == \"l1\" else \"lbfgs\"\n",
    "    # Construction et entra√Ænement du meilleur mod√®le\n",
    "    best_model = LogisticRegression(\n",
    "        C=best_params[\"C\"],\n",
    "        penalty=\"l2\",\n",
    "        solver=best_params[\"solver\"],\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model = best_model.fit(X_train_use, y_train)\n",
    "    print(\"Mod√®le final entra√Æn√© avec best_params\")\n",
    "\n",
    "    # Pr√©dictions\n",
    "    y_train_pred = model.predict(X_train_use)\n",
    "    y_train_pred_proba = model.predict_proba(X_train_use)[:, 1]\n",
    "    y_val_pred = model.predict(X_val_use)\n",
    "    y_val_pred_proba = model.predict_proba(X_val_use)[:, 1]\n",
    "    y_test_pred = model.predict(X_test_use)\n",
    "    y_test_pred_proba = model.predict_proba(X_test_use)[:, 1]\n",
    "\n",
    "    # Calcul des m√©triques\n",
    "    train_accuracy, train_precision, train_recall, train_f1, train_roc_auc = (\n",
    "        calcul_metriques(y_train, y_train_pred, y_train_pred_proba)\n",
    "    )\n",
    "    val_accuracy, val_precision, val_recall, val_f1, val_roc_auc = calcul_metriques(\n",
    "        y_val, y_val_pred, y_val_pred_proba\n",
    "    )\n",
    "    test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = (\n",
    "        calcul_metriques(y_test, y_test_pred, y_test_pred_proba)\n",
    "    )\n",
    "\n",
    "    # Affichage des m√©triques train et test\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\n",
    "        f\"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}\"\n",
    "    )\n",
    "    print(f\"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"Train ROC AUC: {train_roc_auc:.4f}, Test ROC AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "    # M√©triques d'entra√Ænement\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    mlflow.log_metric(\"train_f1\", train_f1)\n",
    "    mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n",
    "\n",
    "    # M√©triques de validation\n",
    "    mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "    mlflow.log_metric(\"val_precision\", val_precision)\n",
    "    mlflow.log_metric(\"val_recall\", val_recall)\n",
    "    mlflow.log_metric(\"val_f1\", val_f1)\n",
    "    mlflow.log_metric(\"val_roc_auc\", val_roc_auc)\n",
    "\n",
    "    # M√©triques de test\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    mlflow.log_metric(\"test_f1\", test_f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n",
    "\n",
    "    # Overfitting check\n",
    "    mlflow.log_metric(\"train_val_accuracy_gap\", train_accuracy - val_accuracy)\n",
    "    mlflow.log_metric(\"val_test_accuracy_gap\", val_accuracy - test_accuracy)\n",
    "    mlflow.log_metric(\"train_val_f1_gap\", train_f1 - val_f1)\n",
    "    mlflow.log_metric(\"val_test_f1_gap\", val_f1 - test_f1)\n",
    "\n",
    "    # Courbe ROC pour tarin, val,test\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for y_true, y_proba, label, color in [\n",
    "        (y_train, y_train_pred_proba, \"Train\", \"blue\"),\n",
    "        (y_val, y_val_pred_proba, \"Validation\", \"green\"),\n",
    "        (y_test, y_test_pred_proba, \"Test\", \"red\"),\n",
    "    ]:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "        auc_score = roc_auc_score(y_true, y_proba)\n",
    "        plt.plot(fpr, tpr, color=color, label=f\"{label} (AUC = {auc_score:.3f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves - Train/Validation/Test\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Sauvegarder l'image\n",
    "    plt.savefig(\"roc_curve_use.png\")\n",
    "    mlflow.log_artifact(\"roc_curve_use.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Sauvegarde du mod√®le\n",
    "    mlflow.sklearn.log_model(\n",
    "        best_model,\n",
    "        name=\"model\",\n",
    "        registered_model_name=f\"use_{EMBEDDING_DIM}d_logreg\",\n",
    "    )\n",
    "    # Taggs\n",
    "    mlflow.set_tags(\n",
    "        {\n",
    "            \"model_type\": \"USE_logreg\",\n",
    "            \"embedding_type\": \"USE\",\n",
    "            \"optimizer\": \"optuna\",\n",
    "            \"dataset\": \"twitter_50K\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0526c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p7_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
