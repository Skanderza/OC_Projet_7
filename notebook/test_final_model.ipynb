{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52623fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/p7_bert/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "from transformers import AutoTokenizer\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "076ecfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/test_50K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7126d5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/skanderzahi/Desktop/P7/projet/mlruns/379503310426968982', creation_time=1760449044952, experiment_id='379503310426968982', last_update_time=1760449044952, lifecycle_stage='active', name='p7_air_paradis', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration MLflow\n",
    "mlflow.set_tracking_uri(\"file:///Users/skanderzahi/Desktop/P7/projet/mlruns\")\n",
    "mlflow.set_experiment(\"p7_air_paradis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93327121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer le meilleur modèle selon test_precision\n",
    "exp = mlflow.get_experiment_by_name(\"p7_air_paradis\")\n",
    "runs_df = mlflow.search_runs(\n",
    "    [exp.experiment_id],\n",
    "    filter_string=\"attributes.status = 'FINISHED'\",\n",
    "    order_by=[\"metrics.test_precision DESC\"],\n",
    "    max_results=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80af93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur modèle : DL_DistilBERT_trainable_EPOCHS_3_128_best\n",
      "Run ID : 14729258203f4ea297b9d998dd3b93ba\n",
      "Test Precision : 0.8542\n"
     ]
    }
   ],
   "source": [
    "best_run_id = runs_df.iloc[0][\"run_id\"]\n",
    "best_model_name = runs_df.iloc[0][\"tags.mlflow.runName\"]\n",
    "best_test_precision = runs_df.iloc[0][\"metrics.test_precision\"]\n",
    "MAX_LENGTH = int(runs_df.iloc[0][\"params.max_length\"])\n",
    "\n",
    "print(f\"Meilleur modèle : {best_model_name}\")\n",
    "print(f\"Run ID : {best_run_id}\")\n",
    "print(f\"Test Precision : {best_test_precision:.4f}\")\n",
    "print(f\"MAX_LENGTH : {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9295a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distilbert_tokenizer/tokenizer_config.json',\n",
       " 'distilbert_tokenizer/special_tokens_map.json',\n",
       " 'distilbert_tokenizer/vocab.txt',\n",
       " 'distilbert_tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialiser le tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Sauvegarder le tokenizer localement\n",
    "tokenizer_path = \"distilbert_tokenizer\"\n",
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93fb0b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer sauvegardé dans MLflow\n",
      "\n",
      "Tokenizer sauvegardé dans : distilbert_tokenizer\n"
     ]
    }
   ],
   "source": [
    "# Ajouter le tokenizer au run MLflow\n",
    "with mlflow.start_run(run_id=best_run_id):\n",
    "    mlflow.log_artifact(tokenizer_path, artifact_path=\"tokenizer\")\n",
    "    print(\"Tokenizer sauvegardé dans MLflow\")\n",
    "\n",
    "print(f\"\\nTokenizer sauvegardé dans : {tokenizer_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da9dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleur modèle : DL_DistilBERT_trainable_EPOCHS_3_128_best\n",
      "Run ID : 14729258203f4ea297b9d998dd3b93ba\n",
      "Test Precision : 0.8542\n",
      "MAX_LENGTH : 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  3.14it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle téléchargé : /var/folders/3g/rdq178bx3690jwjlb35tlzqw0000gp/T/tmpkftvfmls/model/data/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé avec succès !\n",
      "\n",
      "Summary du modèle :\n",
      "Model: \"DistilBERT_Classifier\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 128)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_distil_bert_model (TFDi  TFBaseModelOutput(last_hid   6636288   ['input_ids[0][0]',           \n",
      " stilBertModel)              den_state=(None, 128, 768)   0          'attention_mask[0][0]']      \n",
      "                             , hidden_states=None, atte                                           \n",
      "                             ntions=None)                                                         \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 768)                  0         ['tf_distil_bert_model[0][0]']\n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (None, 768)                  0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  98432     ['dropout_19[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    129       ['dropout_20[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66461441 (253.53 MB)\n",
      "Trainable params: 66461441 (253.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Tokenizer chargé\n"
     ]
    }
   ],
   "source": [
    "# CHARGER LE MODÈLE (Méthode directe avec le chemin local)\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "model_path = client.download_artifacts(best_run_id, \"model/data/model\")\n",
    "\n",
    "print(f\"Modèle téléchargé : {model_path}\")\n",
    "\n",
    "# Charger avec custom_objects pour gérer les couches transformers\n",
    "from transformers import TFDistilBertModel\n",
    "\n",
    "loaded_model = keras.models.load_model(\n",
    "    model_path, custom_objects={\"TFDistilBertModel\": TFDistilBertModel}\n",
    ")\n",
    "\n",
    "print(\"Modèle chargé avec succès !\")\n",
    "print(f\"\\nSummary du modèle :\")\n",
    "loaded_model.summary()\n",
    "\n",
    "# CHARGER LE TOKENIZER\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(\"Tokenizer chargé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f6001",
   "metadata": {},
   "source": [
    "# Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e4b6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, max_length=128):\n",
    "    # Tokenization\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    # Prédiction\n",
    "    prediction = model.predict(\n",
    "        [encoding[\"input_ids\"], encoding[\"attention_mask\"]], verbose=0\n",
    "    )\n",
    "\n",
    "    proba = prediction[0][0]\n",
    "    label = \"Positif\" if proba > 0.5 else \"Négatif\"\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"probabilite\": float(proba),\n",
    "        \"prediction\": label,\n",
    "        \"confiance\": float(max(proba, 1 - proba)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7165abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Texte : This movie was absolutely bad!\n",
      "Prédiction : Négatif\n",
      "Probabilité : 0.0063\n",
      "Confiance : 99.37%\n"
     ]
    }
   ],
   "source": [
    "# TEST SUR UN TEXTE SIMPLE\n",
    "# test_text = \"This movie was absolutely amazing! Best film ever!\"\n",
    "test_text = \"This movie was absolutely bad!\"\n",
    "result = predict_sentiment(test_text, loaded_model, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"\\n Texte : {test_text}\")\n",
    "print(f\"Prédiction : {result['prediction']}\")\n",
    "print(f\"Probabilité : {result['probabilite']:.4f}\")\n",
    "print(f\"Confiance : {result['confiance']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6efd3a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index : 4164\n",
      "Texte : I'm a busy bug lately. tsssssssss! \n",
      "\n",
      "Label réel : Négatif\n",
      "Prédiction : Négatif\n",
      "\n",
      "Probabilité : 0.0427\n",
      "Confiance : 95.73%\n",
      "\n",
      "PRÉDICTION CORRECTE !\n"
     ]
    }
   ],
   "source": [
    "# TEST SUR UN EXEMPLE ALÉATOIRE DU DATAFRAME\n",
    "\n",
    "random_idx = np.random.randint(0, len(df))\n",
    "random_text = df.iloc[random_idx][\"text\"]\n",
    "true_label = df.iloc[random_idx][\"target\"]\n",
    "\n",
    "print(f\"\\nIndex : {random_idx}\")\n",
    "print(f\"Texte : {random_text[:MAX_LENGTH]}\")\n",
    "print(f\"\\nLabel réel : {'Positif' if true_label == 1 else 'Négatif'}\")\n",
    "\n",
    "# Prédiction\n",
    "result = predict_sentiment(random_text, loaded_model, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"Prédiction : {result['prediction']}\")\n",
    "print(f\"\\nProbabilité : {result['probabilite']:.4f}\")\n",
    "print(f\"Confiance : {result['confiance']:.2%}\")\n",
    "\n",
    "# Vérification\n",
    "is_correct = (result[\"prediction\"] == \"Positif\" and true_label == 1) or (\n",
    "    result[\"prediction\"] == \"Négatif\" and true_label == 0\n",
    ")\n",
    "\n",
    "print(f\"\\n{'PRÉDICTION CORRECTE !' if is_correct else 'PRÉDICTION INCORRECTE'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13c00c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. ✅ Texte : hollyoaks was good, got a headache \n",
      "   Vrai: Négatif  | Prédit: Négatif  | Proba: 0.039\n",
      "\n",
      "2. ❌ Texte : Wenn ich &quot;Have you ever seen the rain&quot; hÃ¶re, vermisse ich Stargate.  http://bit.ly/DS7Wv\n",
      "   Vrai: Négatif  | Prédit: Positif  | Proba: 0.535\n",
      "\n",
      "3. ✅ Texte : I have to genius bar my MacBook Pro on saturday. Loud fan sound coming out of left side. \n",
      "   Vrai: Négatif  | Prédit: Négatif  | Proba: 0.117\n",
      "\n",
      "4. ❌ Texte : 3.5 days break :O back to usual life!Some of my friends are becoming prays of fishing in orkut  careful guys,use online account \n",
      "   Vrai: Négatif  | Prédit: Positif  | Proba: 0.738\n",
      "\n",
      "5. ✅ Texte : @SharonMc Great the transplating worked.  I think I'm too heavy handed with the roots when I do it. A lovely memory \n",
      "   Vrai: Positif  | Prédit: Positif  | Proba: 0.959\n",
      "\n",
      "6. ✅ Texte : @amazingphil You should do that!  But, with polka dots. (:\n",
      "   Vrai: Positif  | Prédit: Positif  | Proba: 0.833\n",
      "\n",
      "7. ✅ Texte : Yeah, I got new meds, and they make me a little sleepy, slow, and head-achey. \n",
      "   Vrai: Négatif  | Prédit: Négatif  | Proba: 0.054\n",
      "\n",
      "8. ✅ Texte : @kristenlefauve yes camping! let's go to Tillamook!!  \n",
      "   Vrai: Positif  | Prédit: Positif  | Proba: 0.784\n",
      "\n",
      "9. ❌ Texte : @williams1977:  Go Eggles?  \n",
      "   Vrai: Négatif  | Prédit: Positif  | Proba: 0.918\n",
      "\n",
      "10. ✅ Texte : only just realized that he only took one photo of Derek Grant \n",
      "   Vrai: Négatif  | Prédit: Négatif  | Proba: 0.241\n",
      "\n",
      "================================================================================\n",
      " RÉSULTAT : 7/10 prédictions correctes\n",
      "   Précision sur ces exemples : 70.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# TEST SUR PLUSIEURS EXEMPLES\n",
    "n_samples = 10\n",
    "random_indices = np.random.choice(len(df), n_samples, replace=False)\n",
    "\n",
    "correct_predictions = 0\n",
    "results_list = []\n",
    "\n",
    "for i, idx in enumerate(random_indices, 1):\n",
    "    text = df.iloc[idx][\"text\"]\n",
    "    true_label = df.iloc[idx][\"target\"]\n",
    "\n",
    "    result = predict_sentiment(text, loaded_model, tokenizer, MAX_LENGTH)\n",
    "\n",
    "    is_correct = (result[\"prediction\"] == \"Positif\" and true_label == 1) or (\n",
    "        result[\"prediction\"] == \"Négatif\" and true_label == 0\n",
    "    )\n",
    "\n",
    "    if is_correct:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    true_label_str = \"Positif\" if true_label == 1 else \"Négatif\"\n",
    "    status = \"✅\" if is_correct else \"❌\"\n",
    "\n",
    "    print(f\"\\n{i}. {status} Texte : {text[:MAX_LENGTH]}\")\n",
    "    print(\n",
    "        f\"   Vrai: {true_label_str:8} | Prédit: {result['prediction']:8} | \"\n",
    "        f\"Proba: {result['probabilite']:.3f}\"\n",
    "    )\n",
    "\n",
    "    results_list.append(\n",
    "        {\n",
    "            \"text\": text[:100],\n",
    "            \"true\": true_label_str,\n",
    "            \"predicted\": result[\"prediction\"],\n",
    "            \"proba\": result[\"probabilite\"],\n",
    "            \"correct\": is_correct,\n",
    "        }\n",
    "    )\n",
    "\n",
    "accuracy = correct_predictions / n_samples\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\" RÉSULTAT : {correct_predictions}/{n_samples} prédictions correctes\")\n",
    "print(f\"   Précision sur ces exemples : {accuracy:.1%}\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p7_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
